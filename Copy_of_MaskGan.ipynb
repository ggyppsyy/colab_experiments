{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MaskGan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ggyppsyy/colab_experiments/blob/master/Copy_of_MaskGan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "z2P-3ACjCSc4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import cm\n",
        "import math\n",
        "!pip install dropbox\n",
        "\n",
        "import IPython.display as display\n",
        "\n",
        "import dropbox\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import skimage\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import multiprocessing as mp\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "tf.enable_eager_execution()\n",
        "assert tf.multiply(6, 7).numpy() == 42\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "import time\n",
        "\n",
        "current_milli_time = lambda: str(int(round(time.time())))\n",
        "\n",
        "dbx = dropbox.Dropbox('xxx')\n",
        "\n",
        "dbx.users_get_current_account()\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M0Yf3MRpO_dj",
        "colab_type": "code",
        "outputId": "98bda23d-7f47-4eb8-8d99-b315321e9974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "cell_type": "code",
      "source": [
        "path = '/art/paintings/round1/'\n",
        "response = dbx.files_list_folder(path=path)\n",
        "art_entries = []\n",
        "for entry in response.entries:\n",
        "  art_entries.append(entry.path_lower)\n",
        "art_image_count = len(art_entries)\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "for p in art_entries:\n",
        "    md, res = dbx.files_download(p)\n",
        "    with open(p, 'wb+') as f:\n",
        "        f.write(res.content)\n",
        "art_entries"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/art/paintings/round1/a-glass-1911.jpg!large.jpg',\n",
              " '/art/paintings/round1/bread-and-dish-with-fruits-on-the-table.jpg!large.jpg',\n",
              " '/art/paintings/round1/clarinet-1911.jpg!large.jpg',\n",
              " '/art/paintings/round1/clarinetist.jpg!large.jpg',\n",
              " '/art/paintings/round1/guitar-player-1910.jpg!large.jpg',\n",
              " '/art/paintings/round1/friendship-1908.jpg!large.jpg',\n",
              " '/art/paintings/round1/dance-of-the-veils-1907.jpg!large.jpg',\n",
              " '/art/paintings/round1/girl-with-mandolin-fanny-tellier-1910.jpg!large.jpg',\n",
              " '/art/paintings/round1/man-with-a-guitar-1911-1.jpg!large.jpg',\n",
              " '/art/paintings/round1/harlequinesque-personage-1913.jpg!large.jpg',\n",
              " '/art/paintings/round1/harlequin-leaning-1909.jpg',\n",
              " '/art/paintings/round1/houses-on-the-hill-1909.jpg!large.jpg',\n",
              " '/art/paintings/round1/man-with-guitar-1912.jpg!large.jpg',\n",
              " '/art/paintings/round1/mandolin-1914.jpg!large.jpg',\n",
              " '/art/paintings/round1/my-beautiful-woman-with-guitar-1912.jpg!large.jpg',\n",
              " '/art/paintings/round1/nude-figure.jpg!large.jpg',\n",
              " '/art/paintings/round1/portrait-of-ambroise-vollard-1910.jpg!large.jpg',\n",
              " '/art/paintings/round1/poet-1911.jpg!large.jpg',\n",
              " '/art/paintings/round1/portrait-of-daniel-henry-kahnweiler-1910.jpg!large.jpg',\n",
              " '/art/paintings/round1/seated-female-nude-1910.jpg!large.jpg',\n",
              " '/art/paintings/round1/still-life-with-bottle-of-rum-1911.jpg!large.jpg',\n",
              " '/art/paintings/round1/still-life-with-bottle-of-anis-del-mono-1909.jpg!large.jpg',\n",
              " '/art/paintings/round1/the-mandolinist-1911.jpg!large.jpg',\n",
              " '/art/paintings/round1/table-in-a-cafe-bottle-of-pernod-1912.jpg!large.jpg',\n",
              " '/art/paintings/round1/the-pigeon-pea-1912.jpg!large.jpg',\n",
              " '/art/paintings/round1/the-piano-accordionist-1911.jpg!large.jpg',\n",
              " '/art/paintings/round1/woman-with-guitar-and-piano-1911.jpg!large.jpg',\n",
              " '/art/paintings/round1/woman-sitting-in-an-armchair.jpg!large.jpg',\n",
              " '/art/paintings/round1/violin-1913.jpg!large.jpg',\n",
              " '/art/paintings/round1/william-uhde-1910.jpg!large.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "S1dablEyT5Mq",
        "colab_type": "code",
        "outputId": "3bc782a0-d354-4002-9377-2739596be463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "data_root_orig = tf.keras.utils.get_file('flower_photos',\n",
        "                                         'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz', \n",
        "                                         untar=True)\n",
        "data_root = pathlib.Path(data_root_orig)\n",
        "print(data_root)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.keras/datasets/flower_photos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r0bhc5v8WtxJ",
        "colab_type": "code",
        "outputId": "040f225e-6fb2-434d-b99e-7ba92a5a0d10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "flower_image_paths = list(data_root.glob('*/*'))\n",
        "flower_image_paths = [str(path) for path in flower_image_paths]\n",
        "random.shuffle(flower_image_paths)\n",
        "\n",
        "flower_image_count = len(flower_image_paths)\n",
        "flower_image_count"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3670"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "sunNNy-iGe5j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class GeneratorModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "      super(GeneratorModel, self).__init__(name='GeneratorModel')\n",
        "      filters = [32,48,48,64]\n",
        "      self.defilters = np.array([64,48,32,3])\n",
        "      kernel_sizes = [[3,3],[3,3],[3,3],[3,3]]\n",
        "      self.cnn1 = layers.Conv2D(filters=filters[0],\n",
        "                                kernel_size=kernel_sizes[0],\n",
        "                                activation=None,\n",
        "                                padding='same')\n",
        "      self.norm1 = layers.BatchNormalization()\n",
        "      self.pool1 = layers.MaxPool2D(padding='same')\n",
        "      self.cnn2 = layers.Conv2D(filters=filters[1],\n",
        "                                kernel_size=kernel_sizes[1],\n",
        "                                strides=1,\n",
        "                                activation=None,\n",
        "                                padding='same')\n",
        "      self.norm2 = layers.BatchNormalization()\n",
        "      self.pool2 = layers.MaxPool2D(padding='same')\n",
        "      self.cnn3 = layers.Conv2D(filters=filters[2],\n",
        "                                kernel_size=kernel_sizes[2],\n",
        "                                strides=1,\n",
        "                                activation=None,\n",
        "                                padding='same')\n",
        "      self.norm3 = layers.BatchNormalization()\n",
        "      self.pool3 = layers.MaxPool2D(padding='same')\n",
        "      self.cnn4 = layers.Conv2D(filters=filters[3],\n",
        "                                kernel_size=kernel_sizes[3],\n",
        "                                strides=1,\n",
        "                                activation=None,\n",
        "                                padding='same')\n",
        "      self.norm4 = layers.BatchNormalization()\n",
        "      self.pool4 = layers.MaxPool2D(padding='same')\n",
        "      self.cnn5 = layers.Conv2D(filters=filters[3],\n",
        "                                kernel_size=kernel_sizes[3],\n",
        "                                strides=1,\n",
        "                                activation=None,\n",
        "                                padding='same')\n",
        "      self.norm5 = layers.BatchNormalization()\n",
        "      self.pool5 = layers.MaxPool2D(padding='same')\n",
        "      self.cnn6 = layers.Conv2D(filters=filters[3],\n",
        "                                kernel_size=kernel_sizes[3],\n",
        "                                strides=1,\n",
        "                                activation=None,\n",
        "                                padding='same')\n",
        "      self.norm7 = layers.BatchNormalization()\n",
        "      self.upsample1 = layers.UpSampling2D()\n",
        "      self.trans1 = layers.Conv2D(filters=self.defilters[0], \n",
        "                                           kernel_size=kernel_sizes[0],\n",
        "                                           strides = 1,\n",
        "                                           padding='same')\n",
        "      self.upsample1_1 = layers.UpSampling2D()\n",
        "      self.trans1_1 = layers.Conv2D(filters=self.defilters[0], \n",
        "                                           kernel_size=kernel_sizes[0],\n",
        "                                           strides = 1,\n",
        "                                           padding='same')\n",
        "      self.norm5 = layers.BatchNormalization() \n",
        "      self.upsample2 = layers.UpSampling2D()\n",
        "      self.trans2 = layers.Conv2D(filters=self.defilters[1],\n",
        "                                           kernel_size=kernel_sizes[1],\n",
        "                                           strides = 1,\n",
        "                                           padding='same')\n",
        "      self.upsample2_1 = layers.UpSampling2D()\n",
        "      self.trans2_1 = layers.Conv2D(filters=self.defilters[0], \n",
        "                                           kernel_size=kernel_sizes[0],\n",
        "                                           strides = 1,\n",
        "                                           padding='same')\n",
        "      self.norm6 = layers.BatchNormalization() \n",
        "      self.upsample3 = layers.UpSampling2D()\n",
        "      self.trans3 = layers.Conv2D(filters=self.defilters[2],\n",
        "                                           kernel_size=kernel_sizes[2],\n",
        "                                           strides = 1,\n",
        "                                           padding='same')\n",
        "      self.trans3_1 = layers.Conv2D(filters=self.defilters[0], \n",
        "                                           kernel_size=kernel_sizes[0],\n",
        "                                           strides = 1,\n",
        "                                           padding='same')\n",
        "      self.norm7 = layers.BatchNormalization() \n",
        "      self.trans4 = layers.Conv2D(filters=self.defilters[3],\n",
        "                                           kernel_size=kernel_sizes[3],\n",
        "                                           strides = 1,\n",
        "                                           padding='same')\n",
        "      self.trans4_1 = layers.Conv2D(filters=self.defilters[0], \n",
        "                                           kernel_size=kernel_sizes[0],\n",
        "                                           strides = 1,\n",
        "                                           padding='same')\n",
        "      self.norm8 = layers.BatchNormalization() \n",
        "      self.final_conv = layers.Conv2D(filters=self.defilters[3],\n",
        "                                  kernel_size=[1,1],\n",
        "                                  padding='same')\n",
        "      \n",
        "      \n",
        "    def call(self, inputs, training=False):\n",
        "      x = self.cnn1(inputs)\n",
        "      if (training):\n",
        "          x = self.norm1(x)\n",
        "      x1 = tf.keras.activations.selu(x)\n",
        "      x = self.cnn2(self.pool1(x1))\n",
        "      if (training):\n",
        "          x = self.norm2(x)\n",
        "      x2 = tf.keras.activations.selu(x)\n",
        "      x = self.cnn3(self.pool2(x2))\n",
        "      if (training):\n",
        "          x = self.norm3(x)\n",
        "      x3 = tf.keras.activations.selu(x)\n",
        "      x = self.cnn4(self.pool3(x3))\n",
        "      if (training):\n",
        "          x = self.norm4(x)\n",
        "      x = tf.keras.activations.tanh(x)\n",
        "      x = self.cnn5(self.pool4(x))\n",
        "      if (training):\n",
        "          x = self.norm5(x)\n",
        "      x = tf.keras.activations.tanh(x)\n",
        "      x = self.cnn6(self.pool5(x))\n",
        "      if (training):\n",
        "          x = self.norm6(x)\n",
        "      x = tf.keras.activations.tanh(x)\n",
        "      x = self.upsample1(x)\n",
        "      x = self.trans1(x)\n",
        "      x = tf.keras.activations.selu(x)\n",
        "      x = self.upsample1_1(x)\n",
        "      x = self.trans1_1(x)\n",
        "      if (training):\n",
        "          x = self.norm5(x)\n",
        "      x = tf.keras.activations.selu(x)\n",
        "      x = self.upsample2(x)\n",
        "      x = tf.concat([x, x3],axis=-1)\n",
        "      x = self.trans2(x)\n",
        "      x = tf.keras.activations.selu(x)\n",
        "      x = self.upsample2_1(x)\n",
        "      x = self.trans2_1(x)\n",
        "      if (training):\n",
        "          x = self.norm6(x)\n",
        "      x = tf.keras.activations.selu(x)\n",
        "      x = tf.concat([x, x2],axis=-1)\n",
        "      x = self.upsample3(x)\n",
        "      x = self.trans3(x)\n",
        "      x = self.trans3_1(x)\n",
        "      if (training):\n",
        "          x = self.norm7(x)\n",
        "      x = tf.keras.activations.selu(x)\n",
        "      x = tf.concat([x, x1],axis=-1)\n",
        "      x = self.trans4(x)\n",
        "      x = self.trans4_1(x)\n",
        "      if (training):\n",
        "          x = self.norm8(x)\n",
        "      x = tf.keras.activations.selu(x)\n",
        "      x = tf.concat([x, inputs],axis=-1)\n",
        "      x = tf.keras.activations.selu(self.final_conv(x))\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hv0_f2JTZMPe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DiscriminatorModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorModel, self).__init__(name='DiscriminatorModel')\n",
        "        filters = [64,64,64,64,64,32,16]\n",
        "        kernel_sizes = [[3,3],[3,3],[3,3],[3,3],[3,3],[3,3],[3,3]]\n",
        "        self.cnn1 = layers.Conv2D(filters=filters[0],\n",
        "                                  kernel_size=kernel_sizes[0],\n",
        "                                  activation=None)\n",
        "        self.norm1 = layers.BatchNormalization()\n",
        "        self.pool1 = layers.MaxPool2D(padding='same')\n",
        "        self.cnn2 = layers.Conv2D(filters=filters[1],\n",
        "                                  kernel_size=kernel_sizes[1],\n",
        "                                  activation=None)\n",
        "        self.norm2 = layers.BatchNormalization()\n",
        "        #self.pool = layers.MaxPool2D(padding='same')\n",
        "        self.cnn3 = layers.Conv2D(filters=filters[2],\n",
        "                                  kernel_size=kernel_sizes[2],\n",
        "                                  activation=None)\n",
        "        self.norm3 = layers.BatchNormalization()\n",
        "        self.pool2 = layers.MaxPool2D(padding='same')\n",
        "        self.cnn4 = layers.Conv2D(filters=filters[3],\n",
        "                                  kernel_size=kernel_sizes[3],\n",
        "                                  activation=None)\n",
        "        self.norm4 = layers.BatchNormalization()\n",
        "        #self.pool = layers.MaxPool2D(padding='same')\n",
        "        self.cnn5 = layers.Conv2D(filters=filters[4],\n",
        "                                  kernel_size=kernel_sizes[4],\n",
        "                                  activation=None)\n",
        "        self.norm5 = layers.BatchNormalization()\n",
        "        self.pool3 = layers.MaxPool2D(padding='same')\n",
        "        self.cnn6 = layers.Conv2D(filters=filters[5],\n",
        "                                   kernel_size=kernel_sizes[5],\n",
        "                                   activation=None)\n",
        "        self.norm6 = layers.BatchNormalization()\n",
        "        self.pool4 = layers.MaxPool2D(padding='same')\n",
        "        self.cnn7 = layers.Conv2D(filters=filters[6],\n",
        "                                  kernel_size=kernel_sizes[6],\n",
        "                                  activation=None)\n",
        "        self.norm7= layers.BatchNormalization()\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.final_dense = layers.Dense(1,activation='sigmoid')\n",
        "      \n",
        "    def call(self, inputs, training=False):\n",
        "        x = tf.keras.activations.selu(self.norm1(self.cnn1(inputs)))\n",
        "        x = tf.keras.activations.selu(self.norm2(self.cnn2(self.pool1(x))))    \n",
        "        x = tf.keras.activations.selu(self.norm3(self.cnn3(x)))\n",
        "        x = tf.keras.activations.selu(self.norm4(self.cnn4(self.pool2(x))))\n",
        "        x = tf.keras.activations.selu(self.norm5(self.cnn5(x)))\n",
        "        x = tf.keras.activations.selu(self.norm6(self.cnn6(self.pool3(x))))    \n",
        "        x = tf.keras.activations.selu(self.norm7(self.cnn7(self.pool4(x))))\n",
        "        return self.final_dense(self.flatten(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ohMDUmAoGT-A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class GeneratorModelOld(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(GeneratorModel, self).__init__(name='GeneratorModel')\n",
        "        #filters = [256,256,256,256,256]\n",
        "        filters = [64,64,64,64,64]\n",
        "        kernel_sizes = [[1,1],[3,3],[5,5],[7,7],[9,9]]\n",
        "        defilters = [64,3]\n",
        "        self.cnn1 = layers.Conv2D(filters=filters[0],\n",
        "                                  kernel_size=kernel_sizes[0],\n",
        "                                  activation='tanh')\n",
        "        self.cnn2 = layers.Conv2D(filters=filters[1],\n",
        "                                  kernel_size=kernel_sizes[1],\n",
        "                                  strides=1,           \n",
        "                                  padding='same',\n",
        "                                  activation='tanh')\n",
        "        self.cnn3 = layers.Conv2D(filters=filters[2],\n",
        "                                  kernel_size=kernel_sizes[2],\n",
        "                                  strides=1,\n",
        "                                  padding='same',\n",
        "                                  activation='tanh')\n",
        "        self.cnn4 = layers.Conv2D(filters=filters[3],\n",
        "                                  kernel_size=kernel_sizes[3],\n",
        "                                  strides=1,\n",
        "                                  padding='same',\n",
        "                                  activation='tanh')\n",
        "        self.cnn5 = layers.Conv2D(filters=filters[4],\n",
        "                                  kernel_size=kernel_sizes[4],\n",
        "                                  strides=1,\n",
        "                                  padding='same',\n",
        "                                  activation='tanh')\n",
        "        '''self.dense1 = layers.Dense(filters[0],activation='tanh')\n",
        "        self.dense2 = layers.Dense(filters[1],activation='tanh')\n",
        "        self.dense3 = layers.Dense(filters[2],activation='tanh')\n",
        "        self.dense4 = layers.Dense(filters[3],activation='tanh')\n",
        "        self.dense5 = layers.Dense(filters[4],activation='tanh')'''\n",
        "        self.norm1 = layers.BatchNormalization()\n",
        "        self.trans1 = layers.Conv2D(filters=defilters[0],\n",
        "                                    kernel_size=[5,5],\n",
        "                                    strides=1,\n",
        "                                    padding='same',)\n",
        "        self.norm2 = layers.BatchNormalization()\n",
        "        self.trans2 = layers.Conv2D(filters=defilters[0],\n",
        "                                    kernel_size=[5,5],\n",
        "                                    strides=1,\n",
        "                                    padding='same',)\n",
        "        self.norm2 = layers.BatchNormalization()\n",
        "        self.trans3 = layers.Conv2D(filters=defilters[0],\n",
        "                                    kernel_size=[5,5],\n",
        "                                    strides=1,\n",
        "                                    padding='same',)\n",
        "        self.norm2 = layers.BatchNormalization()\n",
        "        self.transfinal = layers.Conv2D(filters=defilters[1],\n",
        "                                        kernel_size=[3,3],\n",
        "                                        strides=1,\n",
        "                                        padding='same',)\n",
        "      \n",
        "      \n",
        "    def call(self, inputs, training=False):\n",
        "        x = inputs\n",
        "        x1 = self.cnn1(x)\n",
        "        x2 = self.cnn2(x)\n",
        "        x3 = self.cnn3(x)\n",
        "        x4 = self.cnn4(x)\n",
        "        x5 = self.cnn5(x)\n",
        "        x = x1 + x2 + x3 + x4 + x5\n",
        "        #tf.broadcast_dynamic_shape(shape_x,shape_y)\n",
        "        x = tf.keras.activations.selu(self.norm2(self.trans1(x)))\n",
        "        return tf.keras.activations.tanh(self.transfinal(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cnSu_olcqLz3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MaskGAN():\n",
        "    def __init__(self, filePaths):\n",
        "        self.tempdir = '/cnn/test/' + current_milli_time() + '/'\n",
        "        self.img_shape = (224, 224, 3)\n",
        "        self.real_images_paths, self.fake_images_paths = filePaths\n",
        "        self.progress = []\n",
        "        self.batch_size = 32\n",
        "        self.last_image_w_h = (0,0)\n",
        "        self.num_samples = 8\n",
        "        self.border_size = 32\n",
        "        \n",
        "        inp = tf.keras.Input(shape=self.img_shape)\n",
        "        discrim = self.createDiscriminator()\n",
        "        validity = discrim(inp)\n",
        "        self.discriminator = tf.keras.Model(inp, validity)\n",
        "        self.discriminator.compile(optimizer=tf.keras.optimizers.Nadam(lr=2e-7),\n",
        "                                   loss='binary_crossentropy',\n",
        "                                   metrics=[\"accuracy\"])\n",
        "        \n",
        "        self.generator = GeneratorModel()\n",
        "        self.generator.compile(optimizer=tf.keras.optimizers.Nadam(lr=2e-5),\n",
        "                               loss=self.generator_loss)\n",
        "        z = tf.keras.Input(shape=self.img_shape)\n",
        "        img = self.generator(z)\n",
        "\n",
        "        self.discriminator.trainable = False\n",
        "        valid = self.discriminator(img)\n",
        "        self.combined = tf.keras.Model(z, valid)\n",
        "        self.combined.compile(optimizer=tf.keras.optimizers.Nadam(lr=2e-5),\n",
        "                              loss='binary_crossentropy')\n",
        "    \n",
        "    \n",
        "    def generator_loss(self, labels, fake_images):\n",
        "        l1_loss = tf.math.reduce_mean(tf.reshape(labels, [-1,]) - tf.reshape(fake_images, [-1,]))\n",
        "        return -l1_loss\n",
        "  \n",
        "    def discriminator_loss(self, labels, preds):\n",
        "        bce = tf.keras.losses.BinaryCrossentropy()\n",
        "        return tf.reduce_mean(bce(labels, preds))\n",
        "      \n",
        "    def createDiscriminator(self):\n",
        "        mobile_net = tf.keras.applications.MobileNet(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "        mobile_net.trainable = True\n",
        "        # Let's take a look to see how many layers are in the base model\n",
        "        print(\"Number of layers in the base model: \", len(mobile_net.layers))\n",
        "\n",
        "        # Fine tune from this layer onwards\n",
        "        fine_tune_at = 65\n",
        "\n",
        "        # Freeze all the layers before the `fine_tune_at` layer\n",
        "        for layer in mobile_net.layers[:fine_tune_at]:\n",
        "            layer.trainable =  False\n",
        "          \n",
        "        return tf.keras.Sequential([mobile_net,\n",
        "                                    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                                    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
        "      \n",
        "      \n",
        "    def trainDiscriminator(self, ds, ds_size=0, epochs=1, batch_size=32):\n",
        "        if (ds_size==0):\n",
        "            steps_per_epoch = 100\n",
        "        else:\n",
        "            steps_per_epoch=tf.ceil(ds_size/batch_size).numpy().astype('int32')\n",
        "        self.discriminator.fit(ds, epochs=epochs, batch_size=batch_size, steps_per_epoch=steps_per_epoch)\n",
        "        \n",
        "    def trainGenerator(self, ds, ds_size=0, epochs=1, batch_size=32):\n",
        "        if (ds_size==0):\n",
        "            steps_per_epoch = 100\n",
        "        else:\n",
        "            steps_per_epoch=tf.ceil(ds_size/batch_size).numpy().astype('int32')\n",
        "        self.generator.fit(ds,epochs=epochs, steps_per_epoch=steps_per_epoch)\n",
        "        \n",
        "        \n",
        "    def train(self, epochs=1, batch_size=32,display_per_epoch=0):\n",
        "          for i in range(epochs):\n",
        "            print(\"Epoch =  %d\" % i)\n",
        "            shape = [None] + list(self.img_shape)\n",
        "            balanced_gen = lambda: self.data_generator(batch_size)\n",
        "            ds = tf.data.Dataset.from_generator(balanced_gen, (tf.float64, tf.float64), (tf.TensorShape(shape), tf.TensorShape([None])))\n",
        "            ds.shuffle(batch_size*batch_size).prefetch(1)\n",
        "            only_false_gen =  lambda: self.data_generator(batch_size,only_fake_images=True)\n",
        "            only_false_ds = tf.data.Dataset.from_generator(only_false_gen, (tf.float64, tf.float64), (tf.TensorShape(shape), tf.TensorShape([None])))\n",
        "            only_false_ds.shuffle(batch_size*batch_size).prefetch(1)\n",
        "            only_true_gen =  lambda: self.data_generator(batch_size,only_true_images=True)\n",
        "            only_true_ds = tf.data.Dataset.from_generator(only_true_gen, (tf.float64, tf.float64), (tf.TensorShape(shape), tf.TensorShape([None])))\n",
        "            only_true_ds.shuffle(batch_size*batch_size).prefetch(1)\n",
        "            gen_data = tf.data.Dataset.from_generator(lambda: self.data_generator_for_l1(batch_size), (tf.float64, tf.float64), (tf.TensorShape(shape), tf.TensorShape(shape)))\n",
        "            gen_data.shuffle(batch_size*batch_size).prefetch(1)\n",
        "            gen_images = self.generator.predict(only_false_ds,steps=1)\n",
        "            gen_images = tf.cast(gen_images, tf.float64)\n",
        "            offset_height = tf.cast(tf.floor((gen_images[0].shape.as_list()[0] - self.img_shape[0]) / 2), tf.int32)\n",
        "            offset_width = tf.cast(tf.floor((gen_images[0].shape.as_list()[1] - self.img_shape[1]) / 2), tf.int32)\n",
        "            gen_images = tf.map_fn(lambda image: tf.image.crop_to_bounding_box(image,offset_height,offset_width,self.img_shape[0],self.img_shape[1]), gen_images)\n",
        "            print(\"Training Discriminator:\")\n",
        "            self.discriminator.fit(ds,steps_per_epoch=1,epochs=1)\n",
        "            #self.discriminator.fit(only_static_gen,steps_per_epoch=1,epochs=1)\n",
        "            self.discriminator.fit(only_true_ds,steps_per_epoch=1,epochs=1)\n",
        "            self.discriminator.fit(gen_images,np.zeros(gen_images.shape[0]),steps_per_epoch=1,epochs=1)\n",
        "            print(\"Training Generator:\")\n",
        "            self.combined.fit(only_false_ds,steps_per_epoch=1,epochs=1)\n",
        "            #self.generator.fit(gen_data,steps_per_epoch=1,epochs=1)\n",
        "            if (display_per_epoch>0 and i%display_per_epoch==0):\n",
        "                for i in range(self.num_samples):\n",
        "                    pred = self.generator.predict(self.data_generator(1, only_fake_images=True), steps=1)\n",
        "                    self.upload_image(pred, self.tempdir + current_milli_time() + '.png')\n",
        "                    time.sleep(.3)\n",
        "    \n",
        "    def data_generator_for_l1(self, batch_size):\n",
        "        if (len(self.real_images_paths)<batch_size):\n",
        "            real_batch_images = np.random.choice(self.real_images_paths, batch_size, replace=True)\n",
        "        else:\n",
        "            real_batch_images = np.random.choice(self.real_images_paths, batch_size, replace=False)\n",
        "        if (len(self.fake_images_paths)<batch_size):\n",
        "            fake_batch_images = np.random.choice(self.fake_images_paths,batch_size, replace=True)\n",
        "        else:\n",
        "            fake_batch_images = np.random.choice(self.fake_images_paths,batch_size, replace=False)\n",
        "        real_batch_images = np.array(real_batch_images)\n",
        "        real_image_ds = np.array(list(map(self.preprocess_image, real_batch_images)))\n",
        "        fake_batch_images = np.array(fake_batch_images)\n",
        "        fake_image_ds = np.array(list(map(self.preprocess_image, fake_batch_images)))\n",
        "        yield fake_image_ds, real_image_ds\n",
        "    \n",
        "    def data_generator(self, batch_size, only_fake_images=False, only_true_images=False, only_static_images=False, staticProportion=0.2):\n",
        "        if (only_true_images==False): num_real = batch_size//2\n",
        "        else: \n",
        "            num_real = batch_size\n",
        "            num_fake = 0\n",
        "            num_static = 0\n",
        "        if (only_fake_images==False): num_fake = batch_size-num_real\n",
        "        else: \n",
        "            num_fake = batch_size\n",
        "            num_real = 0\n",
        "            num_static = 0\n",
        "        if (only_static_images==True):\n",
        "            num_static = batch_size\n",
        "            num_fake = 0\n",
        "            num_real = 0\n",
        "        elif (only_true_images==False and only_fake_images==False):\n",
        "            num_static = int(num_fake * staticProportion)\n",
        "            \n",
        "        final_ds_list = []\n",
        "        final_label_list = []\n",
        "        \n",
        "        if (num_real>0):\n",
        "            if (len(self.real_images_paths)<num_real):\n",
        "                real_batch_images = np.random.choice(self.real_images_paths, num_real, replace=True)\n",
        "            else:\n",
        "                real_batch_images = np.random.choice(self.real_images_paths, num_real, replace=False)\n",
        "            real_batch_images = np.array(real_batch_images)\n",
        "            real_image_ds = np.concatenate(list(map(self.preprocess_image, real_batch_images)), axis=0)\n",
        "            real_labels = np.array(np.ones(real_image_ds.shape[0]))\n",
        "            #print(real_image_ds.shape)\n",
        "            final_ds_list.append(real_image_ds)\n",
        "            final_label_list.append(real_labels)\n",
        "\n",
        "        if (num_fake>0):\n",
        "            if (len(self.fake_images_paths)<num_fake-num_static):\n",
        "                fake_batch_images = np.random.choice(self.fake_images_paths, num_fake-num_static, replace=True)\n",
        "            else:\n",
        "                fake_batch_images = np.random.choice(self.fake_images_paths, num_fake-num_static, replace=False)\n",
        "            fake_batch_images = np.array(fake_batch_images)\n",
        "            fake_image_ds = np.concatenate(list(map(self.preprocess_image, fake_batch_images)), axis=0)\n",
        "            fake_labels = np.array(np.zeros(fake_image_ds.shape[0]))\n",
        "            #print(fake_image_ds.shape)\n",
        "            final_ds_list.append(fake_image_ds)\n",
        "            final_label_list.append(fake_labels)\n",
        "                \n",
        "        if (num_static>0):\n",
        "            static_images = [None for _q in range(num_static)]\n",
        "            for i in range(len(static_images)):\n",
        "                static_images[i] = self.get_static_image(self.img_shape[0],self.img_shape[1])\n",
        "            static_images = np.stack(static_images)\n",
        "            static_images = np.reshape(static_images, (-1,self.img_shape[0],self.img_shape[1],self.img_shape[2]))\n",
        "            static_labels = np.array(np.zeros(num_static))\n",
        "            final_ds_list.append(static_images)\n",
        "            final_label_list.append(static_labels)       \n",
        "        yield np.concatenate(final_ds_list, axis=0),np.concatenate(final_label_list, axis=0)\n",
        "        \n",
        "    def get_static_image(self, final_x, final_y):\n",
        "        return np.random.random_sample((final_x, final_y, 3))\n",
        "    \n",
        "    def get_image(self, image_url, chunk_size=(224,224,3), dropbox=False, show=False):\n",
        "        border_size=self.border_size\n",
        "        if (dropbox):\n",
        "            md, res = dbx.files_download(image_url)\n",
        "            image = Image.open(res.raw)\n",
        "        else: image = Image.open(image_url)\n",
        "        self.last_image_w_h = width, height = image.size\n",
        "        chunk_width,chunk_height,chunk_layers = chunk_size\n",
        "        chunk_width,chunk_height = chunk_width-border_size*2,chunk_height-border_size*2\n",
        "        if (height==None):\n",
        "            print(image_url)\n",
        "        \n",
        "        chunks_wide = math.ceil(width/chunk_width)\n",
        "        chunks_high = math.ceil(height/chunk_height)\n",
        "        \n",
        "        complete_width = chunks_wide * chunk_width\n",
        "        complete_height = chunks_high * chunk_height\n",
        "        \n",
        "        padding = Image.new('RGB',(complete_width+border_size*2,complete_height+border_size*2))\n",
        "        padding_size_w = math.ceil((complete_width-width)/2)\n",
        "        padding_size_h = math.ceil((complete_height-height)/2)\n",
        "        \n",
        "        padding.paste(image, (padding_size_w+border_size,padding_size_h+border_size))\n",
        "        if (show):\n",
        "            display(padding)\n",
        "            \n",
        "        input_images = []\n",
        "        \n",
        "        for i in range(chunks_wide):\n",
        "            for j in range(chunks_high):\n",
        "                input_images.append(np.array(padding.crop((i*chunk_width,\n",
        "                                                           j*chunk_height,\n",
        "                                                           (i+1)*chunk_width+border_size*2,\n",
        "                                                           (j+1)*chunk_height+border_size*2))))\n",
        "        if (show):\n",
        "            for img in input_images:\n",
        "                display(Image.fromarray(img))\n",
        "        \n",
        "        return(np.stack(input_images).astype(np.float))\n",
        "    \n",
        "    def preprocess_image(self, file_address,show=False):\n",
        "        images = self.get_image(file_address, chunk_size=self.img_shape,show=show)\n",
        "        for i in range(images.shape[0]):\n",
        "            images[i] = (2.0 * (images[i] / 255.0)) - 1\n",
        "        return(images)\n",
        "    \n",
        "    #!!!!!!!! Can only recreate the last image processed by get_image !!!!!!!!\n",
        "    def recreate_image(self, images, show=False):\n",
        "        images = tf.map_fn(lambda img: tf.image.crop_to_bounding_box(img,\n",
        "                                                      self.border_size,\n",
        "                                                      self.border_size,\n",
        "                                                      self.img_shape[0]-self.border_size,\n",
        "                                                      self.img_shape[1]-self.border_size), images)\n",
        "        original_width, original_height = self.last_image_w_h\n",
        "        chunk_width,chunk_height,chunk_layers = self.img_shape\n",
        "        chunk_width,chunk_height = chunk_width-self.border_size*2,chunk_height-self.border_size*2\n",
        "        chunks_wide = math.ceil(original_width/chunk_width)\n",
        "        chunks_high = math.ceil(original_height/chunk_height)\n",
        "        backdrop = Image.new('RGB',(chunks_wide * chunk_width,chunks_high * chunk_height))\n",
        "        input_images = []\n",
        "        for i in range(images.shape[0]):\n",
        "            img = ((1 + images[i]) / 2.0) * 255.0\n",
        "            img = np.floor(img).astype(np.uint8)\n",
        "            input_images.append(Image.fromarray(img))\n",
        "        for p in range(chunks_wide):\n",
        "            for q in range(chunks_high):\n",
        "                backdrop.paste(input_images[(p*chunks_high)+q], (p*chunk_width,q*chunk_height))\n",
        "        img = np.array(backdrop)\n",
        "        starty = np.floor((img.shape[0] - original_height) / 2).astype(np.int32)\n",
        "        startx = np.floor((img.shape[1] - original_width) / 2).astype(np.int32)\n",
        "        img = img[starty:starty+original_height,startx:startx+original_width,:]\n",
        "        img = Image.fromarray(img)\n",
        "        if (show):\n",
        "            display(img)\n",
        "        return(img)\n",
        "    \n",
        "    def upload_image(self, images, image_dir):\n",
        "        image = self.recreate_image(images)\n",
        "        try:\n",
        "            os.mkdir('/images/')\n",
        "        except FileExistsError:\n",
        "            pass\n",
        "        image.save('/images/image.png', 'PNG')\n",
        "        with open('/images/image.png', 'rb') as f:\n",
        "            print(image_dir)\n",
        "            dbx.files_upload(f.read(), image_dir, mute=True)\n",
        "        os.remove('/images/image.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nex0ivgnchFM",
        "colab_type": "code",
        "outputId": "633110e2-45fb-4140-abcb-d55ba2e7aea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "maskGan = MaskGAN((art_entries,flower_image_paths))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Number of layers in the base model:  87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "il7jwybQcF5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89423
        },
        "outputId": "468bcf41-3f51-486e-b5e3-e267b36d161e"
      },
      "cell_type": "code",
      "source": [
        "maskGan.train(epochs=1000, batch_size=3,display_per_epoch=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch =  0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, use\n",
            "    tf.py_function, which takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    \n",
            "Training Discriminator:\n",
            "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6200 - acc: 0.6429\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.7522 - acc: 0.3889\n",
            "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.6751 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 11s 11s/step - loss: 0.7012\n",
            "/cnn/test/1554194660/1554194688.png\n",
            "/cnn/test/1554194660/1554194691.png\n",
            "/cnn/test/1554194660/1554194693.png\n",
            "/cnn/test/1554194660/1554194694.png\n",
            "/cnn/test/1554194660/1554194696.png\n",
            "/cnn/test/1554194660/1554194697.png\n",
            "/cnn/test/1554194660/1554194699.png\n",
            "/cnn/test/1554194660/1554194701.png\n",
            "Epoch =  1\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.7671 - acc: 0.4286\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.8256 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6586 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6435\n",
            "Epoch =  2\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6471 - acc: 0.6000\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.8246 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.7439 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.7834\n",
            "Epoch =  3\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.7265 - acc: 0.5417\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.8040 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.7121 - acc: 0.5417\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.6986\n",
            "Epoch =  4\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.6139 - acc: 0.6071\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7790 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.7597 - acc: 0.6111\n",
            "Training Generator:\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.7031\n",
            "Epoch =  5\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.6284 - acc: 0.5357\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.8206 - acc: 0.3636\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.7294 - acc: 0.4500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.6996\n",
            "Epoch =  6\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.6743 - acc: 0.7143\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.8035 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.7117 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6978\n",
            "Epoch =  7\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.5728 - acc: 0.6786\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.7735 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.7337 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.7028\n",
            "Epoch =  8\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.5088 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7949 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.7313 - acc: 0.4583\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 0.6803\n",
            "Epoch =  9\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.6565 - acc: 0.6429\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7882 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.7557 - acc: 0.5357\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6815\n",
            "Epoch =  10\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.6995 - acc: 0.6429\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.8396 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.7169 - acc: 0.4643\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.7231\n",
            "Epoch =  11\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.5795 - acc: 0.6429\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.8715 - acc: 0.3750\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.7417 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.6570\n",
            "Epoch =  12\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.8867 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.7489 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6884 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.7074\n",
            "Epoch =  13\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.7196 - acc: 0.4643\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.8014 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6951 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.6508\n",
            "Epoch =  14\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.6181 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.8376 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.7947 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.7589\n",
            "Epoch =  15\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.8864 - acc: 0.4000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.8144 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6872 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.7392\n",
            "Epoch =  16\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.5994 - acc: 0.6500\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7977 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.6875 - acc: 0.5556\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.6735\n",
            "Epoch =  17\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.7584 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.8277 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.7716 - acc: 0.7222\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 995ms/step - loss: 0.6604\n",
            "Epoch =  18\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.6272 - acc: 0.6250\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7996 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.7348 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.6612\n",
            "Epoch =  19\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.6082 - acc: 0.6667\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.7997 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6971 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6739\n",
            "Epoch =  20\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.5996 - acc: 0.6500\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.8129 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6836 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 0.6846\n",
            "Epoch =  21\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.5767 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.8308 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6626 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.6969\n",
            "Epoch =  22\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.7817 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.8074 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6836 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.6359\n",
            "Epoch =  23\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.6685 - acc: 0.6250\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.8751 - acc: 0.4250\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6636 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.6784\n",
            "Epoch =  24\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.5860 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.8094 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.7608 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6826\n",
            "Epoch =  25\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.7118 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.7711 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.7024 - acc: 0.6111\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.7090\n",
            "Epoch =  26\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.5814 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7580 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.7085 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.7922\n",
            "Epoch =  27\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.8011 - acc: 0.5417\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.8053 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.7323 - acc: 0.6389\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.7760\n",
            "Epoch =  28\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.5087 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.8012 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6779 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.6493\n",
            "Epoch =  29\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.6297 - acc: 0.6667\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.8421 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6483 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.6873\n",
            "Epoch =  30\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.5572 - acc: 0.6875\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7688 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6585 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6820\n",
            "Epoch =  31\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.9254 - acc: 0.3000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.8164 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.7322 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.6584\n",
            "Epoch =  32\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.7289 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.7515 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6652 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.6663\n",
            "Epoch =  33\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.5816 - acc: 0.6389\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7618 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6537 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.7666\n",
            "Epoch =  34\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.6896 - acc: 0.5714\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7862 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.7291 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6621\n",
            "Epoch =  35\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.6137 - acc: 0.6786\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 0.8068 - acc: 0.4318\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6360 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.7577\n",
            "Epoch =  36\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.5784 - acc: 0.8125\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 0.7938 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.7042 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.6580\n",
            "Epoch =  37\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.5998 - acc: 0.6389\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.8164 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.7785 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7069\n",
            "Epoch =  38\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.5648 - acc: 0.7778\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.7629 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.7706 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6739\n",
            "Epoch =  39\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.6314 - acc: 0.6875\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.8034 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.7238 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.7009\n",
            "Epoch =  40\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.6796 - acc: 0.5625\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.8226 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6754 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.7412\n",
            "Epoch =  41\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.4923 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.8013 - acc: 0.3333\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6878 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6461\n",
            "Epoch =  42\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.5568 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.8399 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6827 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6787\n",
            "Epoch =  43\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.9858 - acc: 0.3500\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.7888 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6822 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6960\n",
            "Epoch =  44\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.7667 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.8142 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.7200 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6599\n",
            "Epoch =  45\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.5502 - acc: 0.7812\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.7996 - acc: 0.4000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.7242 - acc: 0.5417\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 522ms/step - loss: 0.7708\n",
            "Epoch =  46\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.6533 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 0.7765 - acc: 0.5227\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6719 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.6736\n",
            "Epoch =  47\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.5972 - acc: 0.6667\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.7754 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.7033 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.7637\n",
            "Epoch =  48\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.6643 - acc: 0.6667\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 0.8032 - acc: 0.4318\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.7447 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.6600\n",
            "Epoch =  49\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.7354 - acc: 0.5556\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.8149 - acc: 0.5208\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.6940 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.6603\n",
            "Epoch =  50\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 1.0031 - acc: 0.2000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7697 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.7087 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6975\n",
            "Epoch =  51\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.5612 - acc: 0.6944\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.8024 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.7278 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.6931\n",
            "Epoch =  52\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.7381 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.8016 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.7036 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.6613\n",
            "Epoch =  53\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.7110 - acc: 0.5357\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.8348 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.7041 - acc: 0.5357\n",
            "Training Generator:\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6627\n",
            "Epoch =  54\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.6780 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.7997 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.7063 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.7158\n",
            "Epoch =  55\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.7003 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.8207 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6859 - acc: 0.4500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.6087\n",
            "Epoch =  56\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.6427 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 0.8081 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6776 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.7226\n",
            "Epoch =  57\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.6032 - acc: 0.7143\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 0.8136 - acc: 0.3409\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6824 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6976\n",
            "Epoch =  58\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.6816 - acc: 0.6786\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7714 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6644 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7493\n",
            "Epoch =  59\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.5895 - acc: 0.6786\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.7732 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6658 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.6615\n",
            "Epoch =  60\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.5944 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.8157 - acc: 0.3333\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6323 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.7282\n",
            "Epoch =  61\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.6865 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.8197 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.7782 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6727\n",
            "Epoch =  62\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.5926 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.8030 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6522 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6550\n",
            "Epoch =  63\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.7213 - acc: 0.5714\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.8066 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6938 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.7179\n",
            "Epoch =  64\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.5602 - acc: 0.7083\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 0.8411 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6442 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.7362\n",
            "Epoch =  65\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.6445 - acc: 0.6667\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.7854 - acc: 0.3611\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6433 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.6502\n",
            "Epoch =  66\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.7099 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 0.8378 - acc: 0.4091\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.7256 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.7701\n",
            "Epoch =  67\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.5128 - acc: 0.7143\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7776 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6377 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.7191\n",
            "Epoch =  68\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.4794 - acc: 0.7778\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.8422 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6551 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 0.6488\n",
            "Epoch =  69\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.7765 - acc: 0.4583\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.8086 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.7345 - acc: 0.5357\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.7242\n",
            "Epoch =  70\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.5756 - acc: 0.7143\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.7994 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6808 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 529ms/step - loss: 0.6370\n",
            "Epoch =  71\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.7782 - acc: 0.5625\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.7485 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.6746 - acc: 0.5556\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.6229\n",
            "Epoch =  72\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.8094 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.7519 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.6371 - acc: 0.6538\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.7469\n",
            "Epoch =  73\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.6536 - acc: 0.5625\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.7823 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6696 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.6424\n",
            "Epoch =  74\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.6022 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7665 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.7160 - acc: 0.5417\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7046\n",
            "Epoch =  75\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.5792 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.7787 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6673 - acc: 0.4167\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.7530\n",
            "Epoch =  76\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.4918 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.8295 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6597 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6742\n",
            "Epoch =  77\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.5831 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 0.7857 - acc: 0.4318\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6474 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.6886\n",
            "Epoch =  78\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.5396 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.7897 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6544 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.6382\n",
            "Epoch =  79\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.5213 - acc: 0.7188\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.8067 - acc: 0.4250\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6394 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6604\n",
            "Epoch =  80\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.6637 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.7911 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.7250 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.6144\n",
            "Epoch =  81\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.4419 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7864 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6318 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.6560\n",
            "Epoch =  82\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.9011 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.7874 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6277 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6566\n",
            "Epoch =  83\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.4650 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.8042 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6545 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.6775\n",
            "Epoch =  84\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3514 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.7984 - acc: 0.5682\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.7174 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 521ms/step - loss: 0.6387\n",
            "Epoch =  85\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.6301 - acc: 0.6111\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.8116 - acc: 0.3636\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6513 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7108\n",
            "Epoch =  86\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.6717 - acc: 0.6875\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7775 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.7050 - acc: 0.5769\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.6477\n",
            "Epoch =  87\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.5651 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.7697 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6892 - acc: 0.4167\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6682\n",
            "Epoch =  88\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.5398 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.7580 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6894 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.7281\n",
            "Epoch =  89\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.4998 - acc: 0.8214\n",
            "Epoch =  90\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.6408 - acc: 0.7083\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7896 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6445 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6685\n",
            "Epoch =  91\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.6786 - acc: 0.6250\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.7859 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6439 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6265\n",
            "Epoch =  92\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.4775 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.8122 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6691 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.7104\n",
            "Epoch =  93\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.7515 - acc: 0.4643\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7939 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6651 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.6973\n",
            "Epoch =  94\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.5722 - acc: 0.7143\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.8208 - acc: 0.4250\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.6684 - acc: 0.6562\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6945\n",
            "Epoch =  95\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.5381 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7833 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6854 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.7392\n",
            "Epoch =  96\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.9622 - acc: 0.3750\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.8563 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6908 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7010\n",
            "Epoch =  97\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.6376 - acc: 0.7143\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.8001 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6974 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.6846\n",
            "Epoch =  98\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.5941 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.7914 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6122 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.7168\n",
            "Epoch =  99\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.8724 - acc: 0.3214\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 0.8189 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.7120 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.6885\n",
            "Epoch =  100\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.6054 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.8121 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.7325 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 596ms/step - loss: 0.6253\n",
            "/cnn/test/1554194660/1554195037.png\n",
            "/cnn/test/1554194660/1554195039.png\n",
            "/cnn/test/1554194660/1554195040.png\n",
            "/cnn/test/1554194660/1554195042.png\n",
            "/cnn/test/1554194660/1554195043.png\n",
            "/cnn/test/1554194660/1554195045.png\n",
            "/cnn/test/1554194660/1554195046.png\n",
            "/cnn/test/1554194660/1554195048.png\n",
            "Epoch =  101\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.5317 - acc: 0.6429\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.8401 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6856 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.7620\n",
            "Epoch =  102\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.5827 - acc: 0.6250\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7998 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6567 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.7005\n",
            "Epoch =  103\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.6161 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.8005 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6869 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 0.6402\n",
            "Epoch =  104\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.5354 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.8151 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.7296 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.7196\n",
            "Epoch =  105\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.4945 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7960 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.7383 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 999ms/step - loss: 0.6787\n",
            "Epoch =  106\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.5700 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7765 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6910 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.7433\n",
            "Epoch =  107\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.6924 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.8043 - acc: 0.3438\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.7099 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.6176\n",
            "Epoch =  108\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.5797 - acc: 0.6786\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.8116 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.7198 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.7270\n",
            "Epoch =  109\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.5367 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 0.7583 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.7189 - acc: 0.4500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6508\n",
            "Epoch =  110\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.4620 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.8069 - acc: 0.4250\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6688 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 534ms/step - loss: 0.7491\n",
            "Epoch =  111\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.4399 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.8128 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.7131 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.6658\n",
            "Epoch =  112\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.5509 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.7893 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.7383 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.7534\n",
            "Epoch =  113\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.6805 - acc: 0.6250\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.8295 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.7689 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.7102\n",
            "Epoch =  114\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.8491 - acc: 0.3750\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7895 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.7614 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6496\n",
            "Epoch =  115\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.5921 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.8122 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6752 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 530ms/step - loss: 0.6942\n",
            "Epoch =  116\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.5256 - acc: 0.7045\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.7956 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.7010 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.6833\n",
            "Epoch =  117\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7349 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7609 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.7256 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6959\n",
            "Epoch =  118\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.5093 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7871 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6556 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.6799\n",
            "Epoch =  119\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.6059 - acc: 0.6250\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7804 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6825 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6690\n",
            "Epoch =  120\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.6648 - acc: 0.6111\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7604 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.7059 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6922\n",
            "Epoch =  121\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.7826 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7977 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.7147 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6923\n",
            "Epoch =  122\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.4848 - acc: 0.7778\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.8003 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6838 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6921\n",
            "Epoch =  123\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.7191 - acc: 0.6071\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.8066 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6935 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.7045\n",
            "Epoch =  124\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.6000 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7871 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6581 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6747\n",
            "Epoch =  125\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.5505 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7747 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.6956 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.7020\n",
            "Epoch =  126\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3904 - acc: 0.9643\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7977 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6921 - acc: 0.6111\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6984\n",
            "Epoch =  127\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.5913 - acc: 0.6071\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.8066 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6713 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.7155\n",
            "Epoch =  128\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4834 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.7841 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.7021 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6910\n",
            "Epoch =  129\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.4231 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7768 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6662 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7011\n",
            "Epoch =  130\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.6082 - acc: 0.5714\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 0.8369 - acc: 0.4091\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.7189 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6964\n",
            "Epoch =  131\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.6626 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.8466 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6870 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7201\n",
            "Epoch =  132\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.4434 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7815 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6627 - acc: 0.6875\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 0.6485\n",
            "Epoch =  133\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.6257 - acc: 0.6667\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.8006 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.6790 - acc: 0.5938\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.7297\n",
            "Epoch =  134\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.6305 - acc: 0.6786\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.8184 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.7195 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6985\n",
            "Epoch =  135\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.5051 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.8199 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6733 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.7118\n",
            "Epoch =  136\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.6460 - acc: 0.6500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.8174 - acc: 0.3611\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.7305 - acc: 0.4500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6337\n",
            "Epoch =  137\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.5125 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.8037 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.7255 - acc: 0.4167\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.7296\n",
            "Epoch =  138\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.6519 - acc: 0.6429\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.8082 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.7563 - acc: 0.4500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.6768\n",
            "Epoch =  139\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.5544 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.7483 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.7128 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.6682\n",
            "Epoch =  140\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.6698 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.8062 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.7075 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7100\n",
            "Epoch =  141\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.5236 - acc: 0.8125\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.8027 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6974 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.7081\n",
            "Epoch =  142\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.6536 - acc: 0.6429\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.8107 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6748 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6571\n",
            "Epoch =  143\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.5520 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.8327 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6918 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.6876\n",
            "Epoch =  144\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.5181 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7968 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6912 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.6896\n",
            "Epoch =  145\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.6576 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7742 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6350 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.6382\n",
            "Epoch =  146\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.7655 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 255ms/step - loss: 0.8288 - acc: 0.4545\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6809 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.6589\n",
            "Epoch =  147\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.7728 - acc: 0.4583\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 0.8080 - acc: 0.3182\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6922 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6700\n",
            "Epoch =  148\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.5983 - acc: 0.6500\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.7924 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6408 - acc: 0.8333\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.7084\n",
            "Epoch =  149\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.7314 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.7887 - acc: 0.3438\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6578 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.7060\n",
            "Epoch =  150\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.5962 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.8025 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6608 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6524\n",
            "Epoch =  151\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.6976 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.7895 - acc: 0.4792\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6825 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.7427\n",
            "Epoch =  152\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.6198 - acc: 0.6562\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.8056 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.7751 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.6717\n",
            "Epoch =  153\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.5982 - acc: 0.7188\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.8016 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6749 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.6180\n",
            "Epoch =  154\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.6836 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.7648 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.7198 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.6745\n",
            "Epoch =  155\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.7189 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.8090 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6428 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6933\n",
            "Epoch =  156\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.7213 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.8271 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6365 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.7070\n",
            "Epoch =  157\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.6650 - acc: 0.6111\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.7744 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6694 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7288\n",
            "Epoch =  158\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.6125 - acc: 0.6786\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.8100 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6581 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.6631\n",
            "Epoch =  159\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.6492 - acc: 0.6786\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.8495 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.6938 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6930\n",
            "Epoch =  160\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.3379 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.7935 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.7067 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6458\n",
            "Epoch =  161\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6157 - acc: 0.6111\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.7957 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.7526 - acc: 0.4167\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.6195\n",
            "Epoch =  162\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.8459 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.7907 - acc: 0.4318\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6698 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6403\n",
            "Epoch =  163\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.5581 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.7721 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6653 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6965\n",
            "Epoch =  164\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.7202 - acc: 0.4583\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.8180 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6265 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6289\n",
            "Epoch =  165\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.5289 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7707 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6768 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.6675\n",
            "Epoch =  166\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.6305 - acc: 0.6500\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 0.7738 - acc: 0.4091\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6931 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6703\n",
            "Epoch =  167\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.6534 - acc: 0.5938\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.7857 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6284 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.6857\n",
            "Epoch =  168\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.5857 - acc: 0.6944\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.8215 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6091 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.6733\n",
            "Epoch =  169\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.4423 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7714 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6487 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.6359\n",
            "Epoch =  170\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.6116 - acc: 0.5938\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.7881 - acc: 0.4773\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6834 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6647\n",
            "Epoch =  171\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.8031 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 0.7916 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6771 - acc: 0.5556\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 521ms/step - loss: 0.6788\n",
            "Epoch =  172\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.4947 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7744 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6385 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6867\n",
            "Epoch =  173\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.6144 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.7428 - acc: 0.3929\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6974 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.6273\n",
            "Epoch =  174\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.5513 - acc: 0.7222\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7784 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.7051 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6983\n",
            "Epoch =  175\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.6639 - acc: 0.5938\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.8036 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6792 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.6683\n",
            "Epoch =  176\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.5786 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.7827 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6721 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7271\n",
            "Epoch =  177\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.5997 - acc: 0.6786\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.7960 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6999 - acc: 0.5357\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6683\n",
            "Epoch =  178\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.5228 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.8076 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6425 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.6752\n",
            "Epoch =  179\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.7044 - acc: 0.5625\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.8468 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6241 - acc: 0.6111\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.6628\n",
            "Epoch =  180\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.4901 - acc: 0.7143\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.8091 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.6415 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.6067\n",
            "Epoch =  181\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.6031 - acc: 0.7143\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.8018 - acc: 0.3611\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6220 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.6435\n",
            "Epoch =  182\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.5429 - acc: 0.6944\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.8140 - acc: 0.4250\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6687 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.6629\n",
            "Epoch =  183\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.5650 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7540 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6762 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6492\n",
            "Epoch =  184\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.4658 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7727 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.6877 - acc: 0.6111\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.6273\n",
            "Epoch =  185\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.5017 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.7824 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6252 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6595\n",
            "Epoch =  186\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.6104 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7276 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6658 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.6738\n",
            "Epoch =  187\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.5632 - acc: 0.6500\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7909 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.7126 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6384\n",
            "Epoch =  188\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6040 - acc: 0.6667\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7571 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6617 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.6389\n",
            "Epoch =  189\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.5542 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.7860 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6485 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.6704\n",
            "Epoch =  190\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.4878 - acc: 0.8889\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7810 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6437 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.6757\n",
            "Epoch =  191\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.5412 - acc: 0.6786\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 0.8211 - acc: 0.3636\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6590 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.6261\n",
            "Epoch =  192\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.6323 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.7811 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.6785 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6871\n",
            "Epoch =  193\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.6685 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.8019 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.6299 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6566\n",
            "Epoch =  194\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.3876 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.7856 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.6518 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.6353\n",
            "Epoch =  195\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.5092 - acc: 0.7778\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7736 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6982 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.6322\n",
            "Epoch =  196\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.5129 - acc: 0.7143\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.7507 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6117 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.6319\n",
            "Epoch =  197\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.6292 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7728 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.7219 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.6514\n",
            "Epoch =  198\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.7033 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 0.7644 - acc: 0.4318\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.7246 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6519\n",
            "Epoch =  199\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.6248 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.8001 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6871 - acc: 0.6875\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.6214\n",
            "Epoch =  200\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.6951 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.7668 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.6555 - acc: 0.6944\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 0.6560\n",
            "/cnn/test/1554194660/1554195401.png\n",
            "/cnn/test/1554194660/1554195403.png\n",
            "/cnn/test/1554194660/1554195404.png\n",
            "/cnn/test/1554194660/1554195405.png\n",
            "/cnn/test/1554194660/1554195407.png\n",
            "/cnn/test/1554194660/1554195409.png\n",
            "/cnn/test/1554194660/1554195410.png\n",
            "/cnn/test/1554194660/1554195411.png\n",
            "Epoch =  201\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.4055 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 0.7727 - acc: 0.3409\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6459 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6934\n",
            "Epoch =  202\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.5224 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.8148 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6148 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.6757\n",
            "Epoch =  203\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.6530 - acc: 0.6500\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7607 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5971 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6755\n",
            "Epoch =  204\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.6149 - acc: 0.6429\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.7057 - acc: 0.5625\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6948 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6644\n",
            "Epoch =  205\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.6982 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.8209 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.7018 - acc: 0.4167\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 531ms/step - loss: 0.6046\n",
            "Epoch =  206\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.8377 - acc: 0.4583\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.7393 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6360 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6279\n",
            "Epoch =  207\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.4289 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7930 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6959 - acc: 0.4167\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6537\n",
            "Epoch =  208\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.7424 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 0.8209 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6276 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6702\n",
            "Epoch =  209\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.6254 - acc: 0.6923\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7657 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6552 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.6931\n",
            "Epoch =  210\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.5294 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7950 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6452 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6307\n",
            "Epoch =  211\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.7120 - acc: 0.5455\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7844 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.6133 - acc: 0.7188\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.6764\n",
            "Epoch =  212\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.4786 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.7974 - acc: 0.3864\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6951 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 995ms/step - loss: 0.6925\n",
            "Epoch =  213\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3967 - acc: 0.9167\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.8339 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6984 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6130\n",
            "Epoch =  214\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.4698 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 0.7862 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6420 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.6382\n",
            "Epoch =  215\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.7214 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.8084 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6303 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6135\n",
            "Epoch =  216\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.6193 - acc: 0.6786\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7960 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6646 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6373\n",
            "Epoch =  217\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.4953 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7591 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6822 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6484\n",
            "Epoch =  218\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.5527 - acc: 0.6667\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.7400 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6721 - acc: 0.5357\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6396\n",
            "Epoch =  219\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.5532 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.8151 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6632 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6692\n",
            "Epoch =  220\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.3314 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 0.8103 - acc: 0.4091\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.6735 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6529\n",
            "Epoch =  221\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 0.5864 - acc: 0.5750\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.8033 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5984 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6423\n",
            "Epoch =  222\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.5750 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.7516 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6073 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6633\n",
            "Epoch =  223\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.6021 - acc: 0.6667\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.8544 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6572 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6023\n",
            "Epoch =  224\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.5429 - acc: 0.7778\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.8215 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.6567 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 604ms/step - loss: 0.6771\n",
            "Epoch =  225\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.6266 - acc: 0.6786\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.7666 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.6599 - acc: 0.6111\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6506\n",
            "Epoch =  226\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.4606 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.8344 - acc: 0.3438\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6629 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.6584\n",
            "Epoch =  227\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.4266 - acc: 0.8750\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.8091 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6513 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 529ms/step - loss: 0.6717\n",
            "Epoch =  228\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.4865 - acc: 0.7778\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7869 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6383 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5895\n",
            "Epoch =  229\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.4359 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.7660 - acc: 0.4250\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6540 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6527\n",
            "Epoch =  230\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.4661 - acc: 0.7917\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.7802 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.7279 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6442\n",
            "Epoch =  231\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.7500 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7910 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6411 - acc: 0.5417\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6535\n",
            "Epoch =  232\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.5544 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7708 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6698 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6511\n",
            "Epoch =  233\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.5175 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.8173 - acc: 0.5750\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.7162 - acc: 0.4167\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6532\n",
            "Epoch =  234\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.5308 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7645 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6225 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6383\n",
            "Epoch =  235\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.6700 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.8209 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.6313 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.6786\n",
            "Epoch =  236\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.5566 - acc: 0.7917\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7625 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.6494 - acc: 0.5556\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.6915\n",
            "Epoch =  237\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.5314 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.7888 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6439 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6433\n",
            "Epoch =  238\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.7410 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.8213 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6046 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.6487\n",
            "Epoch =  239\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.5346 - acc: 0.6786\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.8032 - acc: 0.4773\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6586 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6116\n",
            "Epoch =  240\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3865 - acc: 0.9583\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7588 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6206 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7298\n",
            "Epoch =  241\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.4822 - acc: 0.8462\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7761 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6790 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.6343\n",
            "Epoch =  242\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3699 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.8091 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6794 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6680\n",
            "Epoch =  243\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.5016 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7834 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6048 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6637\n",
            "Epoch =  244\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.7828 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7911 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6736 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6680\n",
            "Epoch =  245\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.4185 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.7802 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6541 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6310\n",
            "Epoch =  246\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.5548 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.7579 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6554 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.6391\n",
            "Epoch =  247\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.4664 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7830 - acc: 0.4250\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.7060 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6704\n",
            "Epoch =  248\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.7073 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.7567 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6134 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6443\n",
            "Epoch =  249\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.5206 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7651 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6484 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.6372\n",
            "Epoch =  250\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.6144 - acc: 0.6429\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.7821 - acc: 0.4643\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.6135 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6348\n",
            "Epoch =  251\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.5071 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.7754 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6717 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.7067\n",
            "Epoch =  252\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.4309 - acc: 0.8889\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.7654 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6301 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6449\n",
            "Epoch =  253\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.4769 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.7517 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6348 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6103\n",
            "Epoch =  254\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.5127 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.8218 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6287 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6160\n",
            "Epoch =  255\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.4417 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.7745 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5891 - acc: 0.7857\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.6832\n",
            "Epoch =  256\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.5655 - acc: 0.7143\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.7819 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6155 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6359\n",
            "Epoch =  257\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.4691 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 0.8345 - acc: 0.3864\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6315 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.6430\n",
            "Epoch =  258\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.4999 - acc: 0.7917\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.7749 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6555 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.6433\n",
            "Epoch =  259\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.5963 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.7490 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6523 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6340\n",
            "Epoch =  260\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.4597 - acc: 0.8438\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7599 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6705 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 529ms/step - loss: 0.7236\n",
            "Epoch =  261\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.4911 - acc: 0.8462\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 0.7859 - acc: 0.4250\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6450 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.6144\n",
            "Epoch =  262\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.4322 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.8320 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.6004 - acc: 0.6154\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6297\n",
            "Epoch =  263\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.4444 - acc: 0.9167\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 0.8411 - acc: 0.4091\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6128 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.7174\n",
            "Epoch =  264\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.4277 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.8136 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6417 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6575\n",
            "Epoch =  265\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.5908 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.8202 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.7429 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.6643\n",
            "Epoch =  266\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.3846 - acc: 0.9167\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.7613 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6465 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6749\n",
            "Epoch =  267\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.5251 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.7586 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6168 - acc: 0.6875\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6087\n",
            "Epoch =  268\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.5640 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7700 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.5972 - acc: 0.6111\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6285\n",
            "Epoch =  269\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.5046 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.7839 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6582 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.6300\n",
            "Epoch =  270\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4657 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.7811 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6230 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.6271\n",
            "Epoch =  271\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.5047 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.7919 - acc: 0.3864\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6990 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6366\n",
            "Epoch =  272\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.4589 - acc: 0.8125\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.7967 - acc: 0.5750\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5818 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.6467\n",
            "Epoch =  273\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.5567 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.8111 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5925 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 529ms/step - loss: 0.6603\n",
            "Epoch =  274\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.4169 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.7757 - acc: 0.4091\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.6146 - acc: 0.6875\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 0.6834\n",
            "Epoch =  275\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.5200 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.7817 - acc: 0.6250\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6079 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 0.5944\n",
            "Epoch =  276\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.6411 - acc: 0.6562\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.8053 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6586 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.6095\n",
            "Epoch =  277\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.4327 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7912 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6027 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 0.6507\n",
            "Epoch =  278\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.5032 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 255ms/step - loss: 0.7935 - acc: 0.3636\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6555 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6276\n",
            "Epoch =  279\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.7827 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.7679 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6239 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.6824\n",
            "Epoch =  280\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.4111 - acc: 0.8611\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.7824 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6226 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6614\n",
            "Epoch =  281\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.6486 - acc: 0.6250\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7238 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6299 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.6454\n",
            "Epoch =  282\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.4854 - acc: 0.7778\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.7863 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6256 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.6790\n",
            "Epoch =  283\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.4698 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.7535 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6042 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6109\n",
            "Epoch =  284\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3917 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.7517 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6953 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.6314\n",
            "Epoch =  285\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.6391 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.7270 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6584 - acc: 0.5357\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6080\n",
            "Epoch =  286\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.6539 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7425 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6678 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7381\n",
            "Epoch =  287\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.4381 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 0.8231 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6716 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6320\n",
            "Epoch =  288\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.5439 - acc: 0.6500\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7915 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6667 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.7014\n",
            "Epoch =  289\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.4982 - acc: 0.8077\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.7647 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6249 - acc: 0.5357\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6863\n",
            "Epoch =  290\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.5120 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7997 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6255 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6910\n",
            "Epoch =  291\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.4840 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.8122 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.7026 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6496\n",
            "Epoch =  292\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.6044 - acc: 0.6429\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7725 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6316 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.7205\n",
            "Epoch =  293\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.7360 - acc: 0.4643\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7590 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6262 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6799\n",
            "Epoch =  294\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.6333 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.7957 - acc: 0.5750\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6370 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.6912\n",
            "Epoch =  295\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.5198 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7852 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6440 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 999ms/step - loss: 0.6767\n",
            "Epoch =  296\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.4777 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 0.7589 - acc: 0.4091\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.7027 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6373\n",
            "Epoch =  297\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.5417 - acc: 0.6875\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.8090 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6720 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.6419\n",
            "Epoch =  298\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.4742 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.7727 - acc: 0.4091\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6351 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.7304\n",
            "Epoch =  299\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.5350 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.7253 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6934 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.6747\n",
            "Epoch =  300\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.4395 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.7830 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6128 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.6838\n",
            "/cnn/test/1554194660/1554195812.png\n",
            "/cnn/test/1554194660/1554195813.png\n",
            "/cnn/test/1554194660/1554195815.png\n",
            "/cnn/test/1554194660/1554195817.png\n",
            "/cnn/test/1554194660/1554195818.png\n",
            "/cnn/test/1554194660/1554195820.png\n",
            "/cnn/test/1554194660/1554195821.png\n",
            "/cnn/test/1554194660/1554195823.png\n",
            "Epoch =  301\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.4366 - acc: 0.8250\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.7963 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6414 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.6671\n",
            "Epoch =  302\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.4315 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7978 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6366 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.6663\n",
            "Epoch =  303\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.4465 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.7441 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.7705 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.6768\n",
            "Epoch =  304\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.4240 - acc: 0.8846\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7282 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.7046 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6492\n",
            "Epoch =  305\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.4321 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7448 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.7516 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6794\n",
            "Epoch =  306\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3771 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.7899 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6287 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 538ms/step - loss: 0.6978\n",
            "Epoch =  307\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.5622 - acc: 0.7188\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.7633 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5942 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6457\n",
            "Epoch =  308\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.6357 - acc: 0.6500\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.8058 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.7620 - acc: 0.5455\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6654\n",
            "Epoch =  309\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.4669 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.8197 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.7466 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.6415\n",
            "Epoch =  310\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.5691 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.8001 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6324 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6475\n",
            "Epoch =  311\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.4545 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.8079 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6394 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.6424\n",
            "Epoch =  312\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.6095 - acc: 0.7188\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.8011 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6498 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6848\n",
            "Epoch =  313\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.5448 - acc: 0.7083\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.8041 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6517 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7046\n",
            "Epoch =  314\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.4961 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.7892 - acc: 0.4000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.6836 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5874\n",
            "Epoch =  315\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.5310 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.7679 - acc: 0.5357\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6486 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.6659\n",
            "Epoch =  316\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.4829 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.8067 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6795 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.6649\n",
            "Epoch =  317\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.6399 - acc: 0.6071\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.8263 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6154 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.6413\n",
            "Epoch =  318\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.4200 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.8128 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6626 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6907\n",
            "Epoch =  319\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.4392 - acc: 0.9375\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7824 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6734 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6736\n",
            "Epoch =  320\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4645 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7771 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6486 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.6339\n",
            "Epoch =  321\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.5666 - acc: 0.6786\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.7805 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6627 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6307\n",
            "Epoch =  322\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.6226 - acc: 0.6250\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7846 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6860 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.6402\n",
            "Epoch =  323\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.4862 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.8186 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.7046 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.6641\n",
            "Epoch =  324\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.5807 - acc: 0.6429\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.7837 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6387 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6863\n",
            "Epoch =  325\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.4815 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.7661 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6135 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 603ms/step - loss: 0.6981\n",
            "Epoch =  326\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.5431 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.7155 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6372 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.6738\n",
            "Epoch =  327\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.7251 - acc: 0.5714\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7597 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6458 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6780\n",
            "Epoch =  328\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.5006 - acc: 0.7917\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7201 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.6393 - acc: 0.5556\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.6718\n",
            "Epoch =  329\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6150 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7320 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5979 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.6651\n",
            "Epoch =  330\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.6287 - acc: 0.6500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.7862 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6545 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6636\n",
            "Epoch =  331\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.4001 - acc: 0.8889\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7337 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6495 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.6899\n",
            "Epoch =  332\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.6610 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7915 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6604 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.5885\n",
            "Epoch =  333\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.4323 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.8106 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6313 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6782\n",
            "Epoch =  334\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 264ms/step - loss: 0.4771 - acc: 0.7955\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7857 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6377 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6186\n",
            "Epoch =  335\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.4413 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7540 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6258 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.6031\n",
            "Epoch =  336\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.5015 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7514 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.6411 - acc: 0.5278\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6137\n",
            "Epoch =  337\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.6352 - acc: 0.5625\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.8157 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6524 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6278\n",
            "Epoch =  338\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.5734 - acc: 0.8125\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.8009 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6490 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 603ms/step - loss: 0.6237\n",
            "Epoch =  339\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.5502 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.7685 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6370 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.6454\n",
            "Epoch =  340\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.5355 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.7553 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6444 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.6376\n",
            "Epoch =  341\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.7337 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.7818 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6191 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6909\n",
            "Epoch =  342\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.5168 - acc: 0.7222\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7500 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6174 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6592\n",
            "Epoch =  343\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.4392 - acc: 0.8438\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7640 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6080 - acc: 0.4500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.6458\n",
            "Epoch =  344\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4367 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.7351 - acc: 0.5625\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.6720 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.6429\n",
            "Epoch =  345\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.4491 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.7756 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5945 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6415\n",
            "Epoch =  346\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.3891 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.7627 - acc: 0.5357\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.7024 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6267\n",
            "Epoch =  347\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.3387 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.7179 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6523 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.6265\n",
            "Epoch =  348\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.7690 - acc: 0.4583\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 0.8120 - acc: 0.4318\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.7060 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.5921\n",
            "Epoch =  349\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.4723 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.7486 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6317 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 0.6810\n",
            "Epoch =  350\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.5266 - acc: 0.6786\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.7496 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6198 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6573\n",
            "Epoch =  351\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6558 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6560\n",
            "Epoch =  352\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.4721 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7878 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6853 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6436\n",
            "Epoch =  353\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.4857 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.7942 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6053 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.6246\n",
            "Epoch =  354\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.6034 - acc: 0.6250\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.7743 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6212 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6258\n",
            "Epoch =  355\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3357 - acc: 0.9643\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.7904 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.6273 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6253\n",
            "Epoch =  356\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.5815 - acc: 0.6500\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.7627 - acc: 0.5938\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6170 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6525\n",
            "Epoch =  357\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.5008 - acc: 0.8125\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.7838 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6189 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1000ms/step - loss: 0.6361\n",
            "Epoch =  358\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.4841 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7684 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5937 - acc: 0.8333\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6168\n",
            "Epoch =  359\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.4578 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.7763 - acc: 0.4318\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6560 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.6387\n",
            "Epoch =  360\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.5291 - acc: 0.8125\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 0.7921 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6164 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6459\n",
            "Epoch =  361\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.5255 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7625 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5966 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6086\n",
            "Epoch =  362\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.4563 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.7377 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.6133 - acc: 0.6923\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6844\n",
            "Epoch =  363\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.4977 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.7577 - acc: 0.5750\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6547 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6603\n",
            "Epoch =  364\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.6094 - acc: 0.7812\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.7723 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6770 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6168\n",
            "Epoch =  365\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.5156 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.7865 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6221 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.6013\n",
            "Epoch =  366\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.4726 - acc: 0.8750\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.7842 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6618 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.6211\n",
            "Epoch =  367\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.4461 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.7548 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6585 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.6462\n",
            "Epoch =  368\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4614 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7677 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5946 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.6240\n",
            "Epoch =  369\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.4056 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7553 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6685 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.6318\n",
            "Epoch =  370\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.5117 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.7475 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6676 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6473\n",
            "Epoch =  371\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.5456 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.7463 - acc: 0.5227\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6642 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6403\n",
            "Epoch =  372\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.4991 - acc: 0.8889\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.7659 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6788 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.7899\n",
            "Epoch =  373\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.4067 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.7997 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6386 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6448\n",
            "Epoch =  374\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.5234 - acc: 0.7917\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.7573 - acc: 0.4250\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.6268 - acc: 0.7083\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6329\n",
            "Epoch =  375\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.5184 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.7344 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.7095 - acc: 0.5909\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.7269\n",
            "Epoch =  376\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.5671 - acc: 0.6500\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7719 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6657 - acc: 0.5357\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.6712\n",
            "Epoch =  377\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.5426 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.7841 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6384 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.6552\n",
            "Epoch =  378\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.4015 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.8059 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6102 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.7095\n",
            "Epoch =  379\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.4862 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.7359 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6505 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6070\n",
            "Epoch =  380\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.6654 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.7562 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6272 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6065\n",
            "Epoch =  381\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.4460 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.7616 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6670 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6810\n",
            "Epoch =  382\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.6250 - acc: 0.6562\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.7470 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6632 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 0.6492\n",
            "Epoch =  383\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.3955 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.7767 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5997 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6877\n",
            "Epoch =  384\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.3823 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.7803 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6814 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.6524\n",
            "Epoch =  385\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.4914 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7689 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6236 - acc: 0.7083\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.5753\n",
            "Epoch =  386\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.5652 - acc: 0.6875\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.7689 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6685 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 529ms/step - loss: 0.6123\n",
            "Epoch =  387\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.5142 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.7772 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6553 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5941\n",
            "Epoch =  388\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.4117 - acc: 0.8611\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.7545 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.6591 - acc: 0.6111\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 530ms/step - loss: 0.6650\n",
            "Epoch =  389\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.5231 - acc: 0.7083\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7386 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6830 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 531ms/step - loss: 0.6668\n",
            "Epoch =  390\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.5633 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7470 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6290 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.5778\n",
            "Epoch =  391\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.4533 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7662 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6938 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.6622\n",
            "Epoch =  392\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.4202 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7658 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6108 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6368\n",
            "Epoch =  393\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.5382 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.7652 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6674 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.6330\n",
            "Epoch =  394\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.4554 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7921 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.7483 - acc: 0.4167\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.6779\n",
            "Epoch =  395\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.4232 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7089 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6457 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.6383\n",
            "Epoch =  396\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.5046 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7655 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6293 - acc: 0.6875\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5735\n",
            "Epoch =  397\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.5732 - acc: 0.7143\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7903 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6381 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5842\n",
            "Epoch =  398\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3856 - acc: 0.9583\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7598 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6743 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 0.6337\n",
            "Epoch =  399\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.6191 - acc: 0.6250\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.8222 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6114 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.5877\n",
            "Epoch =  400\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.4374 - acc: 0.8750\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.8031 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.6237 - acc: 0.7222\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.6337\n",
            "/cnn/test/1554194660/1554196266.png\n",
            "/cnn/test/1554194660/1554196268.png\n",
            "/cnn/test/1554194660/1554196269.png\n",
            "/cnn/test/1554194660/1554196271.png\n",
            "/cnn/test/1554194660/1554196272.png\n",
            "/cnn/test/1554194660/1554196273.png\n",
            "/cnn/test/1554194660/1554196275.png\n",
            "/cnn/test/1554194660/1554196276.png\n",
            "Epoch =  401\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.5717 - acc: 0.6500\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.7995 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.6059 - acc: 0.6389\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6467\n",
            "Epoch =  402\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.6003 - acc: 0.6071\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.7488 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5806 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.6050\n",
            "Epoch =  403\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.4134 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7453 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.6185 - acc: 0.7188\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 0.5541\n",
            "Epoch =  404\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.4177 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7693 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6652 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.5973\n",
            "Epoch =  405\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.4399 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.8025 - acc: 0.4545\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5724 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6017\n",
            "Epoch =  406\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.4309 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7696 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5902 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.6061\n",
            "Epoch =  407\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.5249 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7294 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6210 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6490\n",
            "Epoch =  408\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.4756 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7879 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6063 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.7044\n",
            "Epoch =  409\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.4958 - acc: 0.7308\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.7779 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6055 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6105\n",
            "Epoch =  410\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.4462 - acc: 0.8056\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.7390 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5998 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6261\n",
            "Epoch =  411\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.3855 - acc: 0.8462\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 0.7470 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6260 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.6200\n",
            "Epoch =  412\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.4859 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.7409 - acc: 0.4545\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.5967 - acc: 0.6875\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6648\n",
            "Epoch =  413\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.4959 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.7406 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6955 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6368\n",
            "Epoch =  414\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.4326 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.7552 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6065 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6523\n",
            "Epoch =  415\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.4512 - acc: 0.8125\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7755 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6166 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6338\n",
            "Epoch =  416\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.4252 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7531 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6638 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6458\n",
            "Epoch =  417\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.4272 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.7851 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5813 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.6623\n",
            "Epoch =  418\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.5584 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7383 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6395 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.6744\n",
            "Epoch =  419\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4289 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.7957 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6596 - acc: 0.8333\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.6361\n",
            "Epoch =  420\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4197 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7453 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6346 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 532ms/step - loss: 0.6784\n",
            "Epoch =  421\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.4616 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.7410 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6748 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.6133\n",
            "Epoch =  422\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.4099 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.7611 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5497 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.6808\n",
            "Epoch =  423\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.6752 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.7744 - acc: 0.4250\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6380 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 529ms/step - loss: 0.6324\n",
            "Epoch =  424\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.4468 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.7818 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6150 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.6477\n",
            "Epoch =  425\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.5350 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.7948 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6174 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6748\n",
            "Epoch =  426\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.3908 - acc: 0.9062\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.7658 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6618 - acc: 0.4167\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.6359\n",
            "Epoch =  427\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.4264 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.7382 - acc: 0.5625\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6269 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.6650\n",
            "Epoch =  428\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3915 - acc: 0.9643\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7825 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6746 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.5975\n",
            "Epoch =  429\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.4971 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.7464 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6606 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.6596\n",
            "Epoch =  430\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.5305 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.7192 - acc: 0.5938\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5758 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6040\n",
            "Epoch =  431\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.3904 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.7740 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6653 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6209\n",
            "Epoch =  432\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.5079 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.7126 - acc: 0.4643\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6135 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6139\n",
            "Epoch =  433\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.5462 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.7860 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6502 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5804\n",
            "Epoch =  434\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4711 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7772 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.6628 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.6587\n",
            "Epoch =  435\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.4807 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.7864 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5948 - acc: 0.7857\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6310\n",
            "Epoch =  436\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.3576 - acc: 0.9643\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7212 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.5867 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.5990\n",
            "Epoch =  437\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.5208 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.8041 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6253 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.6268\n",
            "Epoch =  438\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3950 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7752 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5997 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6101\n",
            "Epoch =  439\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.5114 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.7858 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6227 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.7149\n",
            "Epoch =  440\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.4465 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.7484 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5920 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6509\n",
            "Epoch =  441\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3821 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.7873 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5817 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5766\n",
            "Epoch =  442\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.5346 - acc: 0.6944\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7384 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.6675 - acc: 0.6562\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.5915\n",
            "Epoch =  443\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.5045 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.7330 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6114 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.5968\n",
            "Epoch =  444\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.5376 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7808 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6521 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5962\n",
            "Epoch =  445\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.3125 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.7694 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6431 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 537ms/step - loss: 0.6344\n",
            "Epoch =  446\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.3963 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.7272 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6127 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.6073\n",
            "Epoch =  447\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.4788 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7665 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6161 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.6149\n",
            "Epoch =  448\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4862 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.7585 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6289 - acc: 0.6818\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6426\n",
            "Epoch =  449\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.4778 - acc: 0.7778\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.7438 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5980 - acc: 0.8333\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.6456\n",
            "Epoch =  450\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.4068 - acc: 0.9167\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7711 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6643 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6174\n",
            "Epoch =  451\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.5368 - acc: 0.7083\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.8148 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6297 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.6370\n",
            "Epoch =  452\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.4562 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.7861 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5781 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6315\n",
            "Epoch =  453\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.3311 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.7105 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6076 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.5921\n",
            "Epoch =  454\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3822 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.7952 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5891 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6270\n",
            "Epoch =  455\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3961 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.7228 - acc: 0.6250\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5946 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6695\n",
            "Epoch =  456\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.4412 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7285 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6540 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6122\n",
            "Epoch =  457\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.3086 - acc: 0.9643\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.7566 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6065 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.5782\n",
            "Epoch =  458\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.4867 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.7394 - acc: 0.6250\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6103 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.6384\n",
            "Epoch =  459\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.4425 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7589 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6353 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 522ms/step - loss: 0.5948\n",
            "Epoch =  460\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.5741 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.7601 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6542 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6385\n",
            "Epoch =  461\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.5808 - acc: 0.6500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.8159 - acc: 0.4000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6115 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.6248\n",
            "Epoch =  462\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.3311 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7327 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5669 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.6146\n",
            "Epoch =  463\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.4092 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.7303 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.6503 - acc: 0.5556\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.5923\n",
            "Epoch =  464\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3945 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.7487 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.5867 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.6424\n",
            "Epoch =  465\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4709 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.8033 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6161 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.6565\n",
            "Epoch =  466\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.4241 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.8021 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6033 - acc: 0.8500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 550ms/step - loss: 0.6556\n",
            "Epoch =  467\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.5458 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.8028 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6077 - acc: 0.8333\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.6095\n",
            "Epoch =  468\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3767 - acc: 0.9615\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7729 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.6236 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5906\n",
            "Epoch =  469\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.3551 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7702 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6162 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.6647\n",
            "Epoch =  470\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.4120 - acc: 0.8611\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.7501 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.5822 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6141\n",
            "Epoch =  471\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.4460 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.6968 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6809 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.5266\n",
            "Epoch =  472\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.3987 - acc: 0.8438\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.7743 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6362 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.6000\n",
            "Epoch =  473\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.5019 - acc: 0.8125\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7814 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6502 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6610\n",
            "Epoch =  474\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.5909 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7315 - acc: 0.6111\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5385 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.5939\n",
            "Epoch =  475\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.6431 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7852 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6543 - acc: 0.4643\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.5945\n",
            "Epoch =  476\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.5305 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 255ms/step - loss: 0.7541 - acc: 0.4773\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6786 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.6814\n",
            "Epoch =  477\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.3618 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 0.7933 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.6466 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6411\n",
            "Epoch =  478\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.4131 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7654 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.6502 - acc: 0.6111\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6151\n",
            "Epoch =  479\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.5268 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.8369 - acc: 0.3438\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5817 - acc: 0.7857\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 529ms/step - loss: 0.6462\n",
            "Epoch =  480\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3971 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7662 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6492 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.6364\n",
            "Epoch =  481\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.2927 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7850 - acc: 0.3056\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.7397 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 0.6197\n",
            "Epoch =  482\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.5889 - acc: 0.7917\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.7042 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.5840 - acc: 0.7778\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6249\n",
            "Epoch =  483\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3847 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7500 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6565 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 0.6616\n",
            "Epoch =  484\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.5214 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.8058 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6641 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.6322\n",
            "Epoch =  485\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.5064 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.7847 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6981 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.5715\n",
            "Epoch =  486\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.4124 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7667 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6867 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.6136\n",
            "Epoch =  487\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.3345 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7423 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6174 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.6085\n",
            "Epoch =  488\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.3894 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.7580 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6826 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6741\n",
            "Epoch =  489\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.5204 - acc: 0.7778\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.7970 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5819 - acc: 0.7857\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.6313\n",
            "Epoch =  490\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.5874 - acc: 0.6667\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 0.7657 - acc: 0.4773\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.7221 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.6426\n",
            "Epoch =  491\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 254ms/step - loss: 0.3768 - acc: 0.8636\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7958 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6770 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.6727\n",
            "Epoch =  492\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3065 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7447 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6928 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.7230\n",
            "Epoch =  493\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.5888 - acc: 0.7188\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.7410 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6326 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5732\n",
            "Epoch =  494\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.5409 - acc: 0.8182\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7816 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5824 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.7432\n",
            "Epoch =  495\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.4852 - acc: 0.8125\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7861 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6064 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 7s 7s/step - loss: 0.6492\n",
            "Epoch =  496\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.5143 - acc: 0.7778\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.7418 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.7017 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6607\n",
            "Epoch =  497\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.4010 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7152 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6532 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.6686\n",
            "Epoch =  498\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.5360 - acc: 0.7812\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.7485 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5520 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.7114\n",
            "Epoch =  499\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.4272 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.7138 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5791 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 0.6164\n",
            "Epoch =  500\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.5562 - acc: 0.7222\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.7775 - acc: 0.4000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5765 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.5820\n",
            "/cnn/test/1554194660/1554196749.png\n",
            "/cnn/test/1554194660/1554196751.png\n",
            "/cnn/test/1554194660/1554196752.png\n",
            "/cnn/test/1554194660/1554196753.png\n",
            "/cnn/test/1554194660/1554196755.png\n",
            "/cnn/test/1554194660/1554196756.png\n",
            "/cnn/test/1554194660/1554196758.png\n",
            "/cnn/test/1554194660/1554196759.png\n",
            "Epoch =  501\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.2935 - acc: 0.9444\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.7680 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.7432 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 532ms/step - loss: 0.6064\n",
            "Epoch =  502\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.6759 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.7514 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5972 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6506\n",
            "Epoch =  503\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.3510 - acc: 0.9643\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.7412 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6026 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6141\n",
            "Epoch =  504\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.4560 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.7857 - acc: 0.3929\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6966 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6341\n",
            "Epoch =  505\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.4719 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.7656 - acc: 0.4091\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6300 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6392\n",
            "Epoch =  506\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.4216 - acc: 0.9167\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.7776 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6414 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.6726\n",
            "Epoch =  507\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.6028 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7809 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6262 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6327\n",
            "Epoch =  508\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.3065 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7056 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6623 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5565\n",
            "Epoch =  509\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.5412 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.7277 - acc: 0.4250\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6124 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6604\n",
            "Epoch =  510\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.3547 - acc: 0.8889\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 0.7932 - acc: 0.4318\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.6003 - acc: 0.6538\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.5878\n",
            "Epoch =  511\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.2968 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.7578 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5530 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6252\n",
            "Epoch =  512\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.3791 - acc: 0.8056\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.7670 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6214 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.6213\n",
            "Epoch =  513\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.4622 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.7597 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5977 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6302\n",
            "Epoch =  514\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.6190 - acc: 0.6667\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.7725 - acc: 0.5750\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5828 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.6627\n",
            "Epoch =  515\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.4822 - acc: 0.7917\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.7372 - acc: 0.5227\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5600 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 0.7091\n",
            "Epoch =  516\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.5669 - acc: 0.6786\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.7208 - acc: 0.6111\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5972 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6389\n",
            "Epoch =  517\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.5294 - acc: 0.7778\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.7700 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6166 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 602ms/step - loss: 0.6647\n",
            "Epoch =  518\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.5499 - acc: 0.8125\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.7814 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6085 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6043\n",
            "Epoch =  519\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.4165 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.7992 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6221 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5514\n",
            "Epoch =  520\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.6021 - acc: 0.7143\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.7943 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6591 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6361\n",
            "Epoch =  521\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.4831 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7468 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6040 - acc: 0.5357\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.5537\n",
            "Epoch =  522\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3636 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7433 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6794 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 0.6955\n",
            "Epoch =  523\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.4988 - acc: 0.7778\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.7457 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.6403 - acc: 0.6111\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5975\n",
            "Epoch =  524\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3670 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.8005 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5964 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6010\n",
            "Epoch =  525\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.4054 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.7488 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.7209 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6312\n",
            "Epoch =  526\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.5381 - acc: 0.7222\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.7379 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6309 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 0.5875\n",
            "Epoch =  527\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3905 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.7642 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6470 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6602\n",
            "Epoch =  528\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.4190 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.7210 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.6164 - acc: 0.7778\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.5944\n",
            "Epoch =  529\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.3657 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.7323 - acc: 0.5625\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.7134 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 0.6360\n",
            "Epoch =  530\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.5405 - acc: 0.6429\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.7418 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6033 - acc: 0.8333\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6204\n",
            "Epoch =  531\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.4261 - acc: 0.8750\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7361 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.5951 - acc: 0.7222\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.6879\n",
            "Epoch =  532\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3465 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.7504 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6197 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.6291\n",
            "Epoch =  533\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.6160 - acc: 0.7083\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.7313 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6609 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6364\n",
            "Epoch =  534\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.3693 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.7586 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6121 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5982\n",
            "Epoch =  535\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3474 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7649 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6873 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.5622\n",
            "Epoch =  536\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.4130 - acc: 0.8750\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.7497 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6624 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6196\n",
            "Epoch =  537\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4574 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7433 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6498 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.5863\n",
            "Epoch =  538\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.3608 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7395 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5668 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.7218\n",
            "Epoch =  539\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3414 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7666 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6193 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.5670\n",
            "Epoch =  540\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3543 - acc: 0.9643\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.7679 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6107 - acc: 0.7857\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.5659\n",
            "Epoch =  541\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.4876 - acc: 0.7308\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.7789 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6183 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.7037\n",
            "Epoch =  542\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.4186 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7495 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5476 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 530ms/step - loss: 0.5519\n",
            "Epoch =  543\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.3444 - acc: 0.9167\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.7587 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5389 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.5603\n",
            "Epoch =  544\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.4436 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.7707 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6574 - acc: 0.6364\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.6154\n",
            "Epoch =  545\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.5784 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7413 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6142 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6508\n",
            "Epoch =  546\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.5443 - acc: 0.7222\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.7491 - acc: 0.4545\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5774 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.5628\n",
            "Epoch =  547\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.3624 - acc: 0.9062\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.7530 - acc: 0.5750\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6962 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.6313\n",
            "Epoch =  548\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.3511 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 0.7629 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5589 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.5990\n",
            "Epoch =  549\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3634 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 0.7934 - acc: 0.4773\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6014 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.5877\n",
            "Epoch =  550\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.4641 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7294 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6614 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.5828\n",
            "Epoch =  551\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4440 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.7435 - acc: 0.5750\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6231 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.5972\n",
            "Epoch =  552\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.5259 - acc: 0.7308\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.7492 - acc: 0.4545\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.5951 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6153\n",
            "Epoch =  553\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.3333 - acc: 0.9444\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.7682 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5466 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5535\n",
            "Epoch =  554\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.5701 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7304 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5850 - acc: 0.8500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6042\n",
            "Epoch =  555\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3996 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.8065 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6273 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 530ms/step - loss: 0.6435\n",
            "Epoch =  556\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3317 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7667 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6025 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.6148\n",
            "Epoch =  557\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.4123 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7467 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6869 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.5955\n",
            "Epoch =  558\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3830 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.7445 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5856 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 531ms/step - loss: 0.6719\n",
            "Epoch =  559\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.4945 - acc: 0.6786\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7727 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.6511 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6328\n",
            "Epoch =  560\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.4154 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7531 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6032 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.6264\n",
            "Epoch =  561\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.3493 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.7592 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5877 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6078\n",
            "Epoch =  562\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.4116 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7369 - acc: 0.4375\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6596 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5979\n",
            "Epoch =  563\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.4403 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.7612 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5727 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 529ms/step - loss: 0.6417\n",
            "Epoch =  564\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.4708 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.7259 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5908 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5481\n",
            "Epoch =  565\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.2627 - acc: 0.9643\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 0.7512 - acc: 0.5750\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5838 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.6228\n",
            "Epoch =  566\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3778 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7553 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6258 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.5857\n",
            "Epoch =  567\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.4240 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7441 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5469 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 530ms/step - loss: 0.5660\n",
            "Epoch =  568\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.5247 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 0.7563 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5839 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6051\n",
            "Epoch =  569\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.3844 - acc: 0.8750\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7732 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5922 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.5991\n",
            "Epoch =  570\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.5538 - acc: 0.7778\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.7572 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6206 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.6288\n",
            "Epoch =  571\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.4715 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.7316 - acc: 0.6500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6033 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5766\n",
            "Epoch =  572\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.5526 - acc: 0.7188\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7426 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6432 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.5704\n",
            "Epoch =  573\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3972 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.7456 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5864 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 0.7256\n",
            "Epoch =  574\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.3647 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.7638 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5915 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.6730\n",
            "Epoch =  575\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.3329 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7429 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5853 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.6349\n",
            "Epoch =  576\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3592 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.7739 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6248 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.6354\n",
            "Epoch =  577\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.4309 - acc: 0.9167\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.7459 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5541 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5825\n",
            "Epoch =  578\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.4048 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 0.7000 - acc: 0.6136\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6309 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6259\n",
            "Epoch =  579\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.5518 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.7314 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6338 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.5482\n",
            "Epoch =  580\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.3448 - acc: 0.9375\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.7447 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6085 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.6342\n",
            "Epoch =  581\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.3038 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.7343 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5983 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.5683\n",
            "Epoch =  582\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.4183 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.7541 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6304 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.6544\n",
            "Epoch =  583\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.4098 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7549 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6488 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6026\n",
            "Epoch =  584\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.4656 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.7366 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6014 - acc: 0.5417\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.6020\n",
            "Epoch =  585\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.4798 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.7984 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5908 - acc: 0.7083\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.5609\n",
            "Epoch =  586\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.3696 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7393 - acc: 0.6111\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5268 - acc: 0.8182\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5819\n",
            "Epoch =  587\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.4333 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7755 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5704 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.6368\n",
            "Epoch =  588\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.4707 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.7479 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6731 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.5646\n",
            "Epoch =  589\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3706 - acc: 0.9167\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.7519 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5443 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5619\n",
            "Epoch =  590\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3509 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7846 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5695 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.5865\n",
            "Epoch =  591\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.4540 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.7435 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5978 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.5504\n",
            "Epoch =  592\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.4632 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 0.7285 - acc: 0.5227\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6141 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.6487\n",
            "Epoch =  593\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.2967 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 0.7388 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6107 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6048\n",
            "Epoch =  594\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.5255 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.7592 - acc: 0.4318\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6404 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5897\n",
            "Epoch =  595\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.4295 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 0.7306 - acc: 0.5682\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5965 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6520\n",
            "Epoch =  596\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.3073 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7608 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6011 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.6204\n",
            "Epoch =  597\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 0.3072 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.7448 - acc: 0.5714\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6433 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.5430\n",
            "Epoch =  598\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.4664 - acc: 0.7222\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.7554 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5618 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.6340\n",
            "Epoch =  599\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3462 - acc: 0.9643\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7753 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6105 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5907\n",
            "Epoch =  600\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.4194 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7240 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6867 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6167\n",
            "/cnn/test/1554194660/1554197267.png\n",
            "/cnn/test/1554194660/1554197268.png\n",
            "/cnn/test/1554194660/1554197270.png\n",
            "/cnn/test/1554194660/1554197271.png\n",
            "/cnn/test/1554194660/1554197272.png\n",
            "/cnn/test/1554194660/1554197274.png\n",
            "/cnn/test/1554194660/1554197275.png\n",
            "/cnn/test/1554194660/1554197276.png\n",
            "Epoch =  601\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.3683 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.7414 - acc: 0.6111\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5773 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.7309\n",
            "Epoch =  602\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.4095 - acc: 0.8125\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.7792 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5919 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.5996\n",
            "Epoch =  603\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.4422 - acc: 0.8056\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.7324 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6463 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.5566\n",
            "Epoch =  604\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.6241 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.7504 - acc: 0.4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6206 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5658\n",
            "Epoch =  605\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.4735 - acc: 0.8750\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.7301 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.5790 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5792\n",
            "Epoch =  606\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.3259 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.7256 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5689 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5931\n",
            "Epoch =  607\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3803 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7453 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6172 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.6045\n",
            "Epoch =  608\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.4317 - acc: 0.8438\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.7664 - acc: 0.5750\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6725 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5514\n",
            "Epoch =  609\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.5154 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7925 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6315 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 0.6324\n",
            "Epoch =  610\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.3396 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.7377 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6202 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6149\n",
            "Epoch =  611\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.3912 - acc: 0.8125\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.7235 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.6116 - acc: 0.6875\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 533ms/step - loss: 0.6362\n",
            "Epoch =  612\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.4035 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.7500 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6220 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.6304\n",
            "Epoch =  613\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.3083 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7744 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6320 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6178\n",
            "Epoch =  614\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3267 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7494 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5778 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.5597\n",
            "Epoch =  615\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.3717 - acc: 0.8750\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7553 - acc: 0.6111\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6198 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.5904\n",
            "Epoch =  616\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.4086 - acc: 0.9167\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7858 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.5800 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6147\n",
            "Epoch =  617\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.4477 - acc: 0.7778\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.7455 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6187 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.5802\n",
            "Epoch =  618\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3178 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7543 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5375 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.6274\n",
            "Epoch =  619\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.4093 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.7428 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5499 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5655\n",
            "Epoch =  620\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.4133 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.7519 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5714 - acc: 0.8333\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.5995\n",
            "Epoch =  621\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.4967 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.7716 - acc: 0.4318\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6658 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.6278\n",
            "Epoch =  622\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.4135 - acc: 0.8438\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.7225 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5799 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5921\n",
            "Epoch =  623\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.3571 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.7686 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5712 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.6553\n",
            "Epoch =  624\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3918 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.7590 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5785 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.5701\n",
            "Epoch =  625\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.4429 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7096 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5594 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1000ms/step - loss: 0.6091\n",
            "Epoch =  626\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.3815 - acc: 0.9375\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7063 - acc: 0.6389\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5809 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6317\n",
            "Epoch =  627\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.3607 - acc: 0.9167\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7427 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6568 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.5658\n",
            "Epoch =  628\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.3702 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7475 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6514 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6144\n",
            "Epoch =  629\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.2973 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.7635 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5234 - acc: 0.9000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6107\n",
            "Epoch =  630\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.3207 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7620 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6636 - acc: 0.5625\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 532ms/step - loss: 0.6194\n",
            "Epoch =  631\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.4455 - acc: 0.7222\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7768 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5611 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6051\n",
            "Epoch =  632\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.5382 - acc: 0.6429\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.7704 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5752 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5843\n",
            "Epoch =  633\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.3481 - acc: 0.9375\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7799 - acc: 0.4250\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6710 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.5752\n",
            "Epoch =  634\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.3824 - acc: 0.8611\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7840 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.5541 - acc: 0.8214\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6006\n",
            "Epoch =  635\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.3713 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7714 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6472 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.6975\n",
            "Epoch =  636\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3140 - acc: 0.8750\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.7445 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5694 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5766\n",
            "Epoch =  637\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.2893 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.7854 - acc: 0.5227\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6113 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.5910\n",
            "Epoch =  638\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.4526 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7699 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.6125 - acc: 0.6923\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.6805\n",
            "Epoch =  639\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.3019 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.8030 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6202 - acc: 0.7083\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.7553\n",
            "Epoch =  640\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.2876 - acc: 0.9643\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7829 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5544 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.6400\n",
            "Epoch =  641\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.4266 - acc: 0.8438\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.7003 - acc: 0.6250\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5871 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.5620\n",
            "Epoch =  642\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.5382 - acc: 0.7778\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6898 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.6463 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.5684\n",
            "Epoch =  643\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.4406 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.7575 - acc: 0.4792\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.6086 - acc: 0.6875\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.5665\n",
            "Epoch =  644\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.2956 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7465 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5534 - acc: 0.8214\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.6195\n",
            "Epoch =  645\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.2472 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.7155 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5328 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 450ms/step - loss: 0.6328\n",
            "Epoch =  646\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.2904 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.6980 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.5447 - acc: 0.7188\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6045\n",
            "Epoch =  647\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.4087 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7668 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5665 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5757\n",
            "Epoch =  648\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.4313 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.7240 - acc: 0.5625\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5800 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.6134\n",
            "Epoch =  649\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.3299 - acc: 0.9062\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.8104 - acc: 0.4583\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.5702 - acc: 0.7222\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.7044\n",
            "Epoch =  650\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.4549 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.7157 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5933 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 530ms/step - loss: 0.6285\n",
            "Epoch =  651\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3288 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7435 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5963 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 999ms/step - loss: 0.5844\n",
            "Epoch =  652\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.3488 - acc: 0.9375\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.8101 - acc: 0.5625\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5894 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6040\n",
            "Epoch =  653\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.4763 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7483 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.5679 - acc: 0.8125\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.6011\n",
            "Epoch =  654\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3304 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.6816 - acc: 0.6111\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.5263 - acc: 0.8333\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.5359\n",
            "Epoch =  655\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3622 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.7197 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6079 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.6515\n",
            "Epoch =  656\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.3944 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.7272 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6309 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.5203\n",
            "Epoch =  657\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.4910 - acc: 0.8750\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7441 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5676 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5552\n",
            "Epoch =  658\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.3966 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.7300 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.5481 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.5605\n",
            "Epoch =  659\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3685 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.7184 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6049 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.6135\n",
            "Epoch =  660\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.3615 - acc: 0.9444\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.7722 - acc: 0.4500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5973 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.5871\n",
            "Epoch =  661\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3708 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.7284 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5953 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.6449\n",
            "Epoch =  662\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.3145 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7590 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6427 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.5778\n",
            "Epoch =  663\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.4663 - acc: 0.9375\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.7109 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5937 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5622\n",
            "Epoch =  664\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3030 - acc: 0.9167\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.7578 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5910 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 0.5959\n",
            "Epoch =  665\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.1846 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.7566 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.5978 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.6663\n",
            "Epoch =  666\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.4311 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.7211 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.6016 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5879\n",
            "Epoch =  667\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.5331 - acc: 0.7143\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.7310 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6120 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.5888\n",
            "Epoch =  668\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3149 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 0.7233 - acc: 0.7000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.7113 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.5891\n",
            "Epoch =  669\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.3556 - acc: 0.9375\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7386 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6582 - acc: 0.5500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.5607\n",
            "Epoch =  670\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.4430 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.7414 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5812 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.5751\n",
            "Epoch =  671\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.4501 - acc: 0.9167\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.7486 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6273 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.5991\n",
            "Epoch =  672\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.4968 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.7591 - acc: 0.3889\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5359 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 532ms/step - loss: 0.6868\n",
            "Epoch =  673\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.4562 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7988 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5733 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5206\n",
            "Epoch =  674\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3436 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.7498 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5843 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5973\n",
            "Epoch =  675\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.3736 - acc: 0.9444\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6865 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.5766 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.5787\n",
            "Epoch =  676\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3569 - acc: 0.8750\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.7557 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.6181 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.5690\n",
            "Epoch =  677\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.5055 - acc: 0.7500\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.7454 - acc: 0.5625\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6083 - acc: 0.6429\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.6353\n",
            "Epoch =  678\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.3565 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.7312 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5930 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6133\n",
            "Epoch =  679\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.2519 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.7370 - acc: 0.6250\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5961 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6271\n",
            "Epoch =  680\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.2654 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 0.7378 - acc: 0.5455\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.5507 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.5695\n",
            "Epoch =  681\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.4028 - acc: 0.9375\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.8144 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6317 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5918\n",
            "Epoch =  682\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.3987 - acc: 0.9062\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.7883 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.5723 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.5709\n",
            "Epoch =  683\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.4956 - acc: 0.7222\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.7242 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.5980 - acc: 0.7083\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 547ms/step - loss: 0.5939\n",
            "Epoch =  684\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.3770 - acc: 0.9688\n",
            "1/1 [==============================] - 0s 242ms/step - loss: 0.7355 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.5337 - acc: 0.8611\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6249\n",
            "Epoch =  685\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.5222 - acc: 0.8214\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7568 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.5415 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 531ms/step - loss: 0.6246\n",
            "Epoch =  686\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3933 - acc: 0.8500\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.7568 - acc: 0.5750\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6749 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.5396\n",
            "Epoch =  687\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.2841 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 0.7126 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5819 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 532ms/step - loss: 0.6520\n",
            "Epoch =  688\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.3051 - acc: 0.9375\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.7389 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6344 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.7004\n",
            "Epoch =  689\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.3507 - acc: 0.9167\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7363 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.5753 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.6090\n",
            "Epoch =  690\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3654 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.7122 - acc: 0.4062\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6175 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.5446\n",
            "Epoch =  691\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.3841 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.7626 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6416 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.6080\n",
            "Epoch =  692\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3984 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.7694 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5723 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6380\n",
            "Epoch =  693\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.4072 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.7180 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5664 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.5739\n",
            "Epoch =  694\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.4106 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.7099 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.6791 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.5517\n",
            "Epoch =  695\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3540 - acc: 0.9583\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.7514 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6072 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.5366\n",
            "Epoch =  696\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.6869 - acc: 0.6389\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.7460 - acc: 0.6111\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.5612 - acc: 0.7188\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 529ms/step - loss: 0.5884\n",
            "Epoch =  697\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3102 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7276 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5600 - acc: 0.9000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6148\n",
            "Epoch =  698\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.2495 - acc: 0.9643\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.7236 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6021 - acc: 0.5714\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5729\n",
            "Epoch =  699\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.3261 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7592 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6144 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.5997\n",
            "Epoch =  700\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.4810 - acc: 0.7857\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.7522 - acc: 0.4792\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6090 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5116\n",
            "/cnn/test/1554194660/1554197841.png\n",
            "/cnn/test/1554194660/1554197842.png\n",
            "/cnn/test/1554194660/1554197844.png\n",
            "/cnn/test/1554194660/1554197845.png\n",
            "/cnn/test/1554194660/1554197847.png\n",
            "/cnn/test/1554194660/1554197848.png\n",
            "/cnn/test/1554194660/1554197850.png\n",
            "/cnn/test/1554194660/1554197851.png\n",
            "Epoch =  701\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.3055 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7452 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5626 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.6270\n",
            "Epoch =  702\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.4015 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7371 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6498 - acc: 0.6500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6345\n",
            "Epoch =  703\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.2946 - acc: 0.9167\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7192 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5614 - acc: 0.8333\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 534ms/step - loss: 0.5954\n",
            "Epoch =  704\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3475 - acc: 0.9583\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7620 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5482 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5909\n",
            "Epoch =  705\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.4710 - acc: 0.7778\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.7644 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5979 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.6100\n",
            "Epoch =  706\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.3392 - acc: 0.9643\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.7471 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6167 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.5881\n",
            "Epoch =  707\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.4187 - acc: 0.8929\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7657 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5514 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.6134\n",
            "Epoch =  708\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.3440 - acc: 0.9000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.7717 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5630 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.5260\n",
            "Epoch =  709\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.3366 - acc: 0.9231\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.7487 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5880 - acc: 0.6071\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.5511\n",
            "Epoch =  710\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.3984 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.7865 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6112 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 609ms/step - loss: 0.5961\n",
            "Epoch =  711\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.3170 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.7061 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5959 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5724\n",
            "Epoch =  712\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3098 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.7104 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6023 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6085\n",
            "Epoch =  713\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.5855 - acc: 0.6364\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.7285 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6020 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.6366\n",
            "Epoch =  714\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.4011 - acc: 0.7917\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.7210 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6262 - acc: 0.5833\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.6285\n",
            "Epoch =  715\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3454 - acc: 0.8750\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7779 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6014 - acc: 0.6786\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.5724\n",
            "Epoch =  716\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.4956 - acc: 0.8000\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.7680 - acc: 0.4000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5896 - acc: 0.7083\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6046\n",
            "Epoch =  717\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.3869 - acc: 0.8889\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 0.7436 - acc: 0.5455\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.5734 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.5456\n",
            "Epoch =  718\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.4364 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.7357 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5270 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.6145\n",
            "Epoch =  719\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.3586 - acc: 0.8750\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.7296 - acc: 0.5278\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5086 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5922\n",
            "Epoch =  720\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.3549 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.7153 - acc: 0.4688\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5449 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5495\n",
            "Epoch =  721\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.3701 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.7713 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5633 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5477\n",
            "Epoch =  722\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.3524 - acc: 0.9444\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7617 - acc: 0.5250\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6013 - acc: 0.6000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6033\n",
            "Epoch =  723\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.2921 - acc: 1.0000\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.7027 - acc: 0.6250\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5942 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.5826\n",
            "Epoch =  724\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.3700 - acc: 0.9375\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.8200 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5605 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.6288\n",
            "Epoch =  725\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3829 - acc: 0.9167\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.6997 - acc: 0.4444\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6282 - acc: 0.5000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.5909\n",
            "Epoch =  726\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.6035 - acc: 0.5833\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 0.7129 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5999 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.5604\n",
            "Epoch =  727\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.3219 - acc: 0.9643\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.7701 - acc: 0.4167\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.6371 - acc: 0.4375\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5592\n",
            "Epoch =  728\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.4770 - acc: 0.8333\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.7617 - acc: 0.6000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6341 - acc: 0.7000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.6005\n",
            "Epoch =  729\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.3166 - acc: 0.8889\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7144 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5230 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.5754\n",
            "Epoch =  730\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4447 - acc: 0.8462\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.7203 - acc: 0.5556\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5450 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.6661\n",
            "Epoch =  731\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.2633 - acc: 0.9643\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.7440 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5696 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6563\n",
            "Epoch =  732\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.3804 - acc: 0.8571\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 0.7186 - acc: 0.6364\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6172 - acc: 0.6818\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5885\n",
            "Epoch =  733\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.3654 - acc: 0.9318\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.7712 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.5201 - acc: 0.7500\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5563\n",
            "Epoch =  734\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.3199 - acc: 0.9500\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 0.7193 - acc: 0.4750\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.5392 - acc: 0.7188\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 0.5582\n",
            "Epoch =  735\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.3175 - acc: 0.9643\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.7281 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.6219 - acc: 0.6111\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5698\n",
            "Epoch =  736\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3797 - acc: 0.8750\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.6958 - acc: 0.4722\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.5514 - acc: 0.7143\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.5612\n",
            "Epoch =  737\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3229 - acc: 0.9167\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 0.7391 - acc: 0.5500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.6620 - acc: 0.6250\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.5308\n",
            "Epoch =  738\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.2995 - acc: 0.9286\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.7492 - acc: 0.6111\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5856 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.5650\n",
            "Epoch =  739\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.5316 - acc: 0.7188\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.7473 - acc: 0.5000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5455 - acc: 0.8000\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.5827\n",
            "Epoch =  740\n",
            "Training Discriminator:\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3782 - acc: 0.8750\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.7252 - acc: 0.5312\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5919 - acc: 0.6667\n",
            "Training Generator:\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wYdM7N_T1v6m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "maskGan.train(epochs=1, batch_size=3, display_per_epoch=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BhoLl8fJs70c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "choice = np.random.choice(art_entries)\n",
        "images = maskGan.preprocess_image(choice,show=False)\n",
        "image = maskGan.recreate_image(images,show=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p_Md4zwjagar",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}